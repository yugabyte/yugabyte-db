#!/usr/bin/env python2.7

# Copyright (c) YugaByte, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
# in compliance with the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software distributed under the License
# is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
# or implied.  See the License for the specific language governing permissions and limitations
# under the License.
#
"""A script to manage a local YugaByte cluster.

We will aim to maintain https://docs.yugabyte.com/admin/yb-ctl/ as public facing documentation!

Example use cases:

Creating a cluster with default settings
  yb-ctl start (yb-ctl create)

Creating a cluster with replication factor 5
  yb-ctl --rf 5 start

Creating a cluster with placement_info
  yb-ctl start
  --placement_info "cloud1.region1.zone1,cloud2.region2.zone2,cloud3.region3.zone3"

Creating a cluster with custom_flags
  yb-ctl start --master_flags "flag1=value,flag2=value,flag3=value"
  --tserver_flags "flag1=value,flag2=value,flag3=value"

Destroying a cluster
  yb-ctl destroy

Restart the cluster
  yb-ctl restart

Wipe restart
  yb-ctl wipe_restart

Destroying your local cluster and its data
  yb-ctl destroy

Add node
  yb-ctl add_node (--placement_info "cloud1.region1.zone1")

Stopping node #X from your cluster
  yb-ctl remove_node <node_id>

Start node
  yb-ctl start_node <node_id> (--placement_info "cloud1.region1.zone1")

Stop node
  yb-ctl stop_node <node_id>

Restart node
  yb-ctl restart_node <node_id>

"""

import argparse
import errno
import glob
import logging
import signal
import subprocess
import sys
import time
import os
import shutil
import random
import json


DAEMON_TYPE_MASTER = 'master'
DAEMON_TYPE_TSERVER = 'tserver'

DAEMON_TYPES = [
    DAEMON_TYPE_MASTER,
    DAEMON_TYPE_TSERVER
]

MAX_WAIT_ITERS = 20
SLEEP_TIME_IN_SEC = 1
MAX_WAIT_SECONDS = 45

YB_POSTGRES_PORT = 5433


def is_env_var_true(env_var_name):
    env_var_value = os.getenv(env_var_name)
    return env_var_value and env_var_value.strip().lower() not in ['n', 'no', '0', 'f', 'false']


DISABLE_CALLHOME_ENV_VAR_SET = is_env_var_true('YB_DISABLE_CALLHOME')


class ExitWithError(Exception):
    pass


def get_local_ip(index):
    return "127.0.0.{}".format(index)


def validate_daemon_type(daemon_type):
    if daemon_type not in DAEMON_TYPES:
        raise RuntimeError("Invalid daemon type: '{}'".format(daemon_type))


def get_binary_name_for_daemon_type(daemon_type):
    return "yb-{}".format(daemon_type)


def adjust_env_for_postgres():
    # TODO: we should not need to do this if Linuxbrew's glibc bundled with the YB package has
    # proper access to locale data.
    for k in os.environ.keys():
        if k == 'LANG' or k.startswith('LC_'):
            del os.environ[k]


class SetAndRestoreEnv:
    """A utility class to save environment variables, and optionally set new environment. """
    def __init__(self, new_env=None):
        self.old_env = {}
        self.new_env = new_env

    def __enter__(self):
        for k in os.environ:
            self.old_env[k] = os.environ[k]
        if self.new_env:
            for k in self.new_env:
                v = self.new_env[k]
                if v is None:
                    del os.environ[k]
                else:
                    os.environ[k] = v

    def __exit__(self, type, value, traceback):
        for k in os.environ.keys():
            if k not in self.old_env:
                del os.environ[k]
        for k in self.old_env:
            os.environ[k] = self.old_env[k]


class DaemonId:
    def __init__(self, daemon_type, index):
        validate_daemon_type(daemon_type)

        self.daemon_type = daemon_type
        self.index = index

    def __str__(self):
        return "{}-{}".format(self.daemon_type, self.index)

    def is_master(self):
        return self.daemon_type == DAEMON_TYPE_MASTER

    def is_tserver(self):
        return self.daemon_type == DAEMON_TYPE_TSERVER

    def get_ip_address(self):
        return get_local_ip(self.index)

    def supports_placement(self):
        return self.daemon_type in [DAEMON_TYPE_MASTER, DAEMON_TYPE_TSERVER]


class ClusterOptions:
    def __init__(self):
        self.max_daemon_index = 20
        self.num_shards_per_tserver = None
        self.replication_factor = 3

        self.cluster_base_dir = None

        self.custom_binary_dir = None
        self.script_dir = os.path.dirname(os.path.realpath(__file__))

        if os.environ.get('YB_USE_EXTERNAL_BUILD_ROOT') == '1':
            build_dir = os.path.dirname(self.script_dir) + '__build'
        else:
            build_dir = os.path.join(self.script_dir, "..", "build")

        self.build_bin_dir = os.path.realpath(
                os.path.join(build_dir, "latest", "bin"))

        self.drives = ["disk-{}".format(i) for i in xrange(1, 3)]

        self.placement_cloud = "cloud"
        self.placement_region = "region"
        self.placement_zone = "zone"

        self.require_clock_sync = False

        self.master_addresses = ""
        self.base_ports = {
                DAEMON_TYPE_MASTER: {
                    "http": 7000,
                    "rpc": 7100
                },
                DAEMON_TYPE_TSERVER: {
                    "http": 9000,
                    "rpc": 9100,
                    "redis_http": 11000,
                    "redis_rpc": 6379,
                    "cql_http": 12000,
                    "cql_rpc": 9042,
                    "pgsql_rpc": 5433
                }
        }

        self.master_flags = []
        self.tserver_flags = []
        self.placement_info_raw = ""
        self.placement_info = []
        self.verbose_level = 0
        self.use_cassandra_authentication = False
        self.node_type = DAEMON_TYPE_TSERVER
        self.is_shell_master = False
        self.is_startup_command = False
        self.enable_postgres = False

    def parse_flag_args(self, flag_args):
        flags = [] if flag_args is None else flag_args.split(",")
        return [item.strip() for item in flags]

    def update_options_from_args(self, args):
        self.replication_factor = args.replication_factor
        self.custom_binary_dir = args.binary_dir
        self.cluster_base_dir = args.data_dir
        self.require_clock_sync = args.require_clock_sync
        self.num_shards_per_tserver = args.num_shards_per_tserver

        if hasattr(args, "v"):
            self.verbose_level = args.v

        if hasattr(args, "use_cassandra_authentication"):
            self.use_cassandra_authentication = args.use_cassandra_authentication

        for arg in ["master_flags", "tserver_flags"]:
            try:
                parser_arg = getattr(args, arg)
            except AttributeError:
                parser_arg = None
            setattr(self, arg, self.parse_flag_args(parser_arg))

        try:
            self.placement_info_raw = getattr(args, "placement_info")
            placement_list = self.placement_info_raw.split(",")
        except AttributeError:
            placement_list = []

        for items in placement_list:
            t_item = tuple(items.split("."))
            if len(t_item) != 3:
                raise RuntimeError("Invalid argument: Each entry in placement info should "
                                   "specify cloud, region and zone as cloud.region.zone, "
                                   "seperated by commas")
            self.placement_info.append(t_item)

        if hasattr(args, "master") and args.master:
            self.node_type = DAEMON_TYPE_MASTER

        if hasattr(args, "enable_postgres"):
            self.enable_postgres = args.enable_postgres

    def validate_daemon_type(self, daemon_type):
        if daemon_type not in DAEMON_TYPES:
            raise RuntimeError("Invalid daemon type: {}".format(daemon_type))
        # Validate the binary.
        self.get_server_binary_path(daemon_type)

    def validate_daemon_index(self, daemon_index):
        if daemon_index < 1 or daemon_index > self.max_daemon_index:
            raise RuntimeError("Invalid daemon node_id: {}".format(daemon_index))

    def get_server_binary_path(self, daemon_type):
        return self.get_binary_path(get_binary_name_for_daemon_type(daemon_type))

    def get_binary_path(self, binary_name):
        # If the user specified a custom path, do not default back to anything else.
        if self.custom_binary_dir:
            binary_dirs = [self.custom_binary_dir]
            logging.info("Using custom binaries path: {}".format(self.custom_binary_dir))
        else:
            binary_dirs = [self.script_dir,
                           self.build_bin_dir,
                           os.path.join(self.build_bin_dir, '..', 'postgres', 'bin'),
                           os.path.join(self.script_dir, '..', 'postgres', 'bin')]

        for binary_dir in binary_dirs:
            path = os.path.join(binary_dir, binary_name)
            if not os.path.isfile(path) or not os.access(path, os.X_OK):
                logging.debug("No binary found at {}".format(path))
            else:
                return path
        raise RuntimeError("No binary found for {}. Considered binary directories: {}".format(
            binary_name, binary_dirs))

    def get_base_node_dirs(self, daemon_index):
        return ["{}/node-{}/{}".format(self.cluster_base_dir, daemon_index, drive)
                for drive in self.drives]

    def get_address(self, daemon_id, port_type, include_base_url=False):
        # We index nodes from 1, but we would like to always start from the actual base port for
        # all use cases, hence the -1.
        port_str = str(self.base_ports[daemon_id.daemon_type][port_type])
        base_local_url = daemon_id.get_ip_address()
        return port_str if not include_base_url else "{}:{}".format(base_local_url, port_str)


class ClusterControl:
    def __init__(self):
        self.options = ClusterOptions()
        self.args = None

        self.parser = argparse.ArgumentParser()
        self.subparsers = self.parser.add_subparsers()

        # This is a dictionary serialized into JSON and written to a configuration file in the data
        # directory.
        self.cluster_config = None

        # This is true only for the "create" command.
        self.creating_cluster = False

        self._setup_parsing()

    def setup_base_parser(self, command, help=None):
        subparser = self.subparsers.add_parser(command, help=help)
        func = getattr(self, command, None)
        if not func:
            raise RuntimeError("Invalid command: {}".format(command))
        subparser.set_defaults(func=func)
        return subparser

    def get_cluster_config_file_path(self):
        """
        :return: the path to a "cluster configuration file" that holds various options specified
                 at cluster creation time, e.g. whether PostgreSQL is enabled.
        """
        return os.path.join(self.options.cluster_base_dir, 'cluster_config.json')

    def load_cluster_config(self):
        config_file_path = self.get_cluster_config_file_path()
        if os.path.exists(config_file_path):
            with open(config_file_path) as config_file:
                self.cluster_config = json.load(config_file)
        else:
            # No configuration file -- let's create an empty one.
            self.cluster_config = {}

    def save_cluster_config(self):
        cluster_config_path = self.get_cluster_config_file_path()
        with open(cluster_config_path, 'w') as config_file:
            json.dump(self.cluster_config, config_file)

    def is_postgres_enabled(self):
        return self.cluster_config.get("enable_postgres") or self.options.enable_postgres

    @staticmethod
    def add_extra_flags_arguments(subparser):
        subparser.add_argument(
            "--master_flags", default=None,
            help="Specify extra master flags as a set of key value pairs. "
                 "Format (key=value,key=value)")

        subparser.add_argument(
            "--tserver_flags", default=None,
            help="Specify extra tserver flags as a set of key value pairs. "
                 "Format (key=value,key=value)")

    def _setup_parsing(self):
        """
        Sets up the command-line parser. Called from the constructor.
        """
        self.parser.add_argument(
            "--binary_dir", default=None,
            help="Specify a custom directory in which to find the yugabyte binaries.")
        self.parser.add_argument(
            "--data_dir", default="/tmp/yugabyte-local-cluster",
            help="Specify a custom directory where to store data.")
        self.parser.add_argument(
            "--replication_factor", "--rf", default=3, type=int,
            help="Replication factor for the cluster as well as default number of masters. ")
        self.parser.add_argument(
            "--require_clock_sync", default=False, type=bool,
            help="Use ntpd for clock synchronization. Needed for real time dependent use-cases.")
        self.parser.add_argument(
            "--num_shards_per_tserver", default=2, type=int,
            help="Number of shards (tablets) to start per tablet server for each table.")

        subparsers = {}
        for cmd_name, help in (
                ("create", "Create a new cluster"),
                ("start", "Create a new cluster, or start existing cluster if it already exists."),
                ("stop", "Stops the cluster"),
                ("destroy", "Destroy the current cluster"),
                ("restart", "Restart the current cluster all at once"),
                ("wipe_restart", "Stop the cluster, wipe all data files and start the cluster as"
                                 "before. Will lose all the flags though."),
                ("add_node", "Add a new node to the current cluster"),
                ("remove_node", "Stop a particular node in the cluster."),
                ("start_node", "Start a particular node with flags."),
                # Adding this to keep the start_node/stop_node nomenclature symmetric.
                ("stop_node", "Stop a particular node in the cluster"),
                ("restart_node", "Restart the node specified."),
                ("status", "Get info on the current cluster processes"),
                ("setup_redis", "Setup YugaByte to support Redis API")):

            subparsers[cmd_name] = self.setup_base_parser(cmd_name, help=help)

        # commands that take --master
        per_daemon_commands = ["remove_node", "restart_node", "add_node", "start_node", "stop_node"]
        # commands that take node_id
        node_id_commands = ["remove_node", "restart_node", "start_node", "stop_node"]
        # commands that take placement_info/cassandra auth/verbosity flags.
        startup_commands = ["start", "create", "restart", "wipe_restart",
                            "add_node", "start_node", "restart_node"]

        for cmd in node_id_commands:
            subparsers[cmd].add_argument("node_id", type=int,
                                         help="The id of the tserver/master in range: 1-{}".
                                         format(self.options.max_daemon_index))

        for cmd in per_daemon_commands:
            subparsers[cmd].add_argument(
                "--master", action='store_true', help="Specifies the node type.")

        for cmd in startup_commands:
            subparsers[cmd].add_argument("--placement_info",
                                         help="Specify the placement info in the following format:"
                                         "cloud.region.zone. Can be comma separated "
                                         "in case you would want to pass more than one value.")

            subparsers[cmd].add_argument("--v", default=0, choices=[str(i) for i in range(5)],
                                         help="Specify the verbosity which dictates "
                                         "the amount of logging on servers trace files."
                                         "Default is 0 and maximum is 4.")

            subparsers[cmd].add_argument("--use_cassandra_authentication",
                                         action='store_true',
                                         help="If specified, this flag will be "
                                         "passed down to tservers as true.")

            subparsers[cmd].add_argument("--enable_postgres",
                                         action='store_true',
                                         help="Enable PostgreSQL API.")
            ClusterControl.add_extra_flags_arguments(subparsers[cmd])
            self.options.is_startup_command = True

    def modify_placement_info(self):
        """
        This will use yb-admin to set the cluster config object to the desired placement.

        This assumes you will have called set_master_addresses already!
        """
        if len(self.options.placement_info) > 0:
            yb_admin_binary_path = self.options.get_binary_path("yb-admin")
            cmd = [yb_admin_binary_path, "--master_addresses", self.options.master_addresses,
                   "modify_placement_info", self.options.placement_info_raw,
                   str(self.options.replication_factor)]
            wait_count = 0
            while wait_count < MAX_WAIT_ITERS:
                try:
                    subprocess.check_call(cmd)
                    print ("Successfully modified placement info.")
                    return
                except subprocess.CalledProcessError:
                    wait_count += 1
                    time.sleep(SLEEP_TIME_IN_SEC)
            raise RuntimeError("Could not modify placement info for the cluster.")

    def get_number_of_servers(self, daemon_type):
        return len(glob.glob("{}/*/{}/yb-data/{}".format(
            self.options.cluster_base_dir, self.options.drives[0], daemon_type)))

    def get_pgrep_regex(self, daemon_id):
        return "yb-{} .* --rpc_bind_addresses {}".format(
            daemon_id.daemon_type,
            daemon_id.get_ip_address())

    def get_pid(self, daemon_id):
        try:
            return int(subprocess.check_output(
                ["pgrep", "-f", self.get_pgrep_regex(daemon_id)]))
        except subprocess.CalledProcessError as e:
            # From man pgrep
            #
            # EXIT STATUS
            # 0      One or more processes matched the criteria.
            # 1      No processes matched.
            # 2      Syntax error in the command line.
            # 3      Fatal error: out of memory etc.
            if e.returncode != 1:
                raise RuntimeError("Error during pgrep: {}".format(e.output))
            return 0

    def build_command(self, daemon_id, specific_arg_list):
        node_base_dirs = self.options.get_base_node_dirs(daemon_id.index)
        first_base_dir = node_base_dirs[0]

        binary_path = self.options.get_server_binary_path(daemon_id.daemon_type)
        command_list = [
            # Start with the actual binary
            binary_path
        ]

        command_list += [
            # Add in all the shared flags
            "--fs_data_dirs \"{}\"".format(",".join(node_base_dirs)),
            "--webserver_interface {}".format(daemon_id.get_ip_address()),
            "--rpc_bind_addresses {}".format(daemon_id.get_ip_address()),
            "--v {}".format(self.options.verbose_level)
        ]

        www_path = os.path.realpath(os.path.join(os.path.dirname(binary_path), "..", "www"))
        version_metadata_path = os.path.realpath(
            os.path.join(os.path.dirname(binary_path), ".."))
        command_list.append("--version_file_json_path={}".format(version_metadata_path))
        if os.path.isdir(www_path):
            command_list.append("--webserver_doc_root \"{}\"".format(www_path))
        if DISABLE_CALLHOME_ENV_VAR_SET:
            command_list.append("--callhome_enabled=false")

        # Add custom args per type of server
        command_list.extend(specific_arg_list)

        # Redirect out and err and launch in the background
        command_list.append(">\"{0}/{1}.out\" 2>\"{0}/{1}.err\" &".format(
            first_base_dir, daemon_id.daemon_type))
        return " ".join(command_list)

    @staticmethod
    def customize_flags(flags, extra_flags):
        return flags + ["--{}".format(item) for item in extra_flags]

    def get_master_only_flags(self, daemon_id):
        command_list = [
            "--replication_factor={}".format(self.options.replication_factor),
            "--yb_num_shards_per_tserver {}".format(self.options.num_shards_per_tserver)
        ]

        if not self.options.is_shell_master:
            command_list += ["--master_addresses {}".format(self.options.master_addresses)]

        return self.customize_flags(command_list, self.options.master_flags)

    def get_tserver_only_flags(self, daemon_id):
        daemon_ip_address_str = str(daemon_id.get_ip_address())
        command_list = [
            "--tserver_master_addrs={}".format(self.options.master_addresses),
            "--memory_limit_hard_bytes={}".format(1024 * 1024 * 1024),
            "--yb_num_shards_per_tserver={}".format(self.options.num_shards_per_tserver),
            "--redis_proxy_bind_address=" + daemon_ip_address_str,
            "--cql_proxy_bind_address=" + daemon_ip_address_str,
            "--local_ip_for_outbound_sockets=" + daemon_ip_address_str,
            # TODO ENG-2876: Enable this in master as well.
            "--use_cassandra_authentication={}".format(
                str(self.options.use_cassandra_authentication).lower())
        ]
        if self.is_postgres_enabled():
            command_list += [
                "--start_pgsql_proxy",
                "--pgsql_proxy_bind_address=" + daemon_ip_address_str
            ]
        return self.customize_flags(command_list, self.options.tserver_flags)

    def get_placement_info_flags(self, placement_flags):
        return [
            "--placement_cloud {}".format(placement_flags[0]),
            "--placement_region {}".format(placement_flags[1]),
            "--placement_zone {}".format(placement_flags[2])
        ]

    def set_master_addresses(self, running_only=False):
        """
        :param running_only: if we're only interested in running masters and not in stopped ones
        """
        num_servers = (
            self.options.replication_factor if self.creating_cluster
            else self.get_number_of_servers(DAEMON_TYPE_MASTER)
        )
        self.options.master_addresses = ",".join(
            [self.options.get_address(DaemonId(DAEMON_TYPE_MASTER, i), "rpc", True)
             for i in range(1, num_servers + 1)
             if not running_only or self.get_pid(DaemonId(DAEMON_TYPE_MASTER, i)) > 0])

    def start_daemon(self, daemon_id):
        self.options.validate_daemon_type(daemon_id.daemon_type)
        self.options.validate_daemon_index(daemon_id.index)

        if self.get_pid(daemon_id) > 0:
            logging.info("Server {} already running".format(daemon_id))
            return

        if not os.path.isdir(self.options.cluster_base_dir):
            raise ExitWithError("Found no cluster data at {}, cannot start daemon {}".format(
                self.options.cluster_base_dir, daemon_id))

        for path in self.options.get_base_node_dirs(daemon_id.index):
            if not os.path.exists(path):
                os.makedirs(path)

        if daemon_id.is_master():
            custom_flags = self.get_master_only_flags(daemon_id)
        elif daemon_id.is_tserver():
            custom_flags = self.get_tserver_only_flags(daemon_id)
        else:
            raise ValueError("Invalid daemon id: %s" % daemon_id)
        if len(self.options.placement_info) > 0 and daemon_id.supports_placement():
            mod_val = (daemon_id.index - 1) % len(self.options.placement_info)
            custom_flags.extend(self.get_placement_info_flags(self.options.placement_info[mod_val]))
        command = self.build_command(daemon_id, custom_flags)
        logging.info("Starting {} with:\n{}".format(daemon_id, command))

        with SetAndRestoreEnv():
            adjust_env_for_postgres()
            os.system(command)

    def stop_process(self, pid, name):
        if pid == 0:
            logging.info("{} already stopped".format(name))
            return
        logging.info("Stopping {} PID={}".format(name, pid))
        # Kill the process.
        os.kill(pid, signal.SIGTERM)

        # Wait for process to stop.
        last_msg_time = time.time()

        def print_wait_msg():
            logging.info("Waiting for {} PID={} to stop...".format(name, pid))
            sys.stdout.flush()
            sys.stderr.flush()
        print_wait_msg()

        while True:
            try:
                os.kill(pid, 0)
            except OSError as err:
                if err.errno == errno.ESRCH:
                    return

            time.sleep(0.5)

            current_time = time.time()
            if current_time - last_msg_time >= 1:
                print_wait_msg()
                last_msg_time = current_time

    def stop_daemon(self, daemon_id):
        self.options.validate_daemon_index(daemon_id.index)
        self.stop_process(self.get_pid(daemon_id), "Server {}".format(daemon_id))
        postgres_pid = self.find_postgres_pid(daemon_id)
        if postgres_pid != 0:
            self.stop_process(postgres_pid, "Postmaster for {}".format(daemon_id))

    def find_postgres_pid(self, daemon_id):
        if not daemon_id.is_tserver():
            return 0
        base_dirs = self.options.get_base_node_dirs(daemon_id.index)
        for dir in base_dirs:
            postmaster_pid = os.path.join(dir, "pg_data", "postmaster.pid")
            if os.path.exists(postmaster_pid):
                try:
                    with open(postmaster_pid, 'rt') as inp:
                        return int(inp.readline())
                except OSError as err:
                    logging.info("Failed to read postmaster.pid for {}".format(daemon_id))
                    return 0

    def restart_daemon(self, daemon_id):
        self.stop_daemon(daemon_id)
        self.start_daemon(daemon_id)

    def start_helper(self, server_counts_map):
        if len(self.options.placement_info) > self.options.replication_factor:
            raise RuntimeError("Number of placement info fields is larger than "
                               "the replication factor and hence the number of servers.")

        if os.path.isdir(self.options.cluster_base_dir):
            raise ExitWithError(
                ("Found cluster data at {}, cannot start new cluster. "
                 "Use --data_dir to specify a different data directory "
                 "if necessary, or 'destroy' / 'wipe_restart'."
                 "Commands to wipe out the old directory.").format(
                    self.options.cluster_base_dir))

        os.makedirs(self.options.cluster_base_dir)
        self.for_all_daemons(self.start_daemon, server_counts_map)

    def change_config_if_master(self, daemon_id, cmd_type):
        if daemon_id.daemon_type == DAEMON_TYPE_TSERVER:
            return
        yb_admin_binary_path = self.options.get_binary_path("yb-admin")
        cmd = [yb_admin_binary_path, "--master_addresses", self.options.master_addresses,
               "change_master_config", cmd_type, daemon_id.get_ip_address(),
               str(self.options.base_ports[DAEMON_TYPE_MASTER]["rpc"])]
        wait_count = 0
        while wait_count < MAX_WAIT_ITERS:
            try:
                subprocess.check_call(cmd)
                return
            except subprocess.CalledProcessError:
                wait_count += 1
                time.sleep(SLEEP_TIME_IN_SEC)

    def wait_for_cluster(self):
        # Wait for master leader to be ready, and wait for enough tservers.
        # 'Enough' here means that the number of live tservers
        # should be equal to the replication factor.
        wait_count = 0
        yb_admin_binary_path = self.options.get_binary_path("yb-admin")
        cmd_list_tservers = [yb_admin_binary_path,
                             "--master_addresses",
                             self.options.master_addresses,
                             "list_all_tablet_servers"]
        max_num_tservers = self.get_number_of_servers(DAEMON_TYPE_TSERVER)
        num_alive_ts = None
        num_yb_admin_ts = None
        start_time = time.time()
        while wait_count < MAX_WAIT_ITERS and (time.time() - start_time <= MAX_WAIT_SECONDS):
            try:
                num_alive_ts = sum([self.get_pid(DaemonId(DAEMON_TYPE_TSERVER, i)) > 0
                                    for i in xrange(1, max_num_tservers + 1)])
                logging.info("Waiting until we have enough tablet servers (currently %d)",
                             num_alive_ts)
                # TODO: enhance this to tell us live vs dead.
                # Tablet Server UUID                      RPC Host/Port
                # 5d6cd15e0a6e48aba1c5128869f51328        127.0.0.5:9100
                # d0ed49b225c744f392b95b9d3eb32e64        127.0.0.1:9100
                # 8a46cace5d904423bf80bf1a6fc10d30        127.0.0.3:9100
                # 2dac590eefb3429bb4d315c51e20f774        127.0.0.2:9100
                # cb703e947033465a80c85577501cc93c        127.0.0.4:9100

                proc = subprocess.Popen(
                    cmd_list_tservers, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                output, _ = proc.communicate()
                if proc.returncode:
                    raise subprocess.CalledProcessError(proc.returncode,
                                                        cmd_list_tservers, output=output)
                num_yb_admin_ts = len(output.splitlines()) - 1
                # This will not work if you have stopped/removed a node and the master is still
                # aware of it because we do not have a yb-admin API to return only live tablet
                # servers.
                if num_yb_admin_ts == num_alive_ts:
                    return True
            except subprocess.CalledProcessError:
                pass
            wait_count += 1
            time.sleep(SLEEP_TIME_IN_SEC)
        logging.error("Failed waiting for {} tservers, got {}".format(
            num_alive_ts, num_yb_admin_ts))
        return False

    def wait_for_cluster_or_raise(self):
        if not self.wait_for_cluster():
            raise RuntimeError("Timed out waiting for Yugabyte cluster!")

    def show_node_status(self, daemon_id):
        pid = self.get_pid(daemon_id)

        def get_address(port_type):
            return self.options.get_address(daemon_id, port_type, include_base_url=True)

        if pid == 0:
            logging.info("Server {} is not running".format(daemon_id))
        else:
            info_list = [
                ("type", daemon_id.daemon_type),
                ("node_id", daemon_id.index),
                ("PID", pid),
                ("admin service", "http://" + get_address("http"))
            ]

            if daemon_id.is_tserver():
                info_list.extend([
                    ("cql service", get_address("cql_rpc")),
                    ("redis service", get_address("redis_rpc")),
                ])
                if self.is_postgres_enabled():
                    info_list.append(("pgsql service", get_address("pgsql_rpc")))
            logging.info("Server is running: {}".format(
                ", ".join(["{}={}".format(k, v) for k, v in info_list])))

    def for_all_daemons(self, fn, server_counts_map=None):
        """
        Run the given function for all daemons.
        """
        for daemon_type in DAEMON_TYPES:
            if server_counts_map:
                num_servers = server_counts_map[daemon_type]
            else:
                num_servers = self.get_number_of_servers(daemon_type)

            for daemon_index in range(1, num_servers + 1):
                fn(DaemonId(daemon_type, daemon_index))

    def create(self):
        self.creating_cluster = True
        server_counts = self.options.replication_factor
        self.set_master_addresses()
        self.cluster_config = {
            "enable_postgres": self.options.enable_postgres
        }

        server_counts_map = {
            DAEMON_TYPE_MASTER: server_counts,
            DAEMON_TYPE_TSERVER: server_counts
        }

        self.start_helper(server_counts_map)
        self.modify_placement_info()
        if self.is_postgres_enabled():
            self.run_cluster_wide_postgres_initdb()
        self.save_cluster_config()
        print ("Successfully created a new cluster.")
        if not DISABLE_CALLHOME_ENV_VAR_SET:
            print ("Congratulations on installing YugaByte DB Community Edition. " +
                   "We'd like to welcome you to the community with a free t-shirt " +
                   "and pack of stickers! " +
                   "Please claim your reward here: https://www.yugabyte.com/community-rewards/")

    # Starts as well as creates. Check if the cluster exists.
    # If it does not create it else start the individual daemons.
    def start(self):
        if os.path.isdir(self.options.cluster_base_dir):
            self.set_master_addresses()
            self.for_all_daemons(self.start_daemon)
        else:
            self.create()
        self.modify_placement_info()

    # Stops the cluster.
    def stop(self):
        self.for_all_daemons(self.stop_daemon)

    def destroy(self):
        self.for_all_daemons(self.stop_daemon)

        # Remove the top-level directory.
        top_level = self.options.cluster_base_dir
        if os.path.exists(top_level) and os.path.isdir(top_level):
            logging.info("Removing base directory: {}".format(top_level))
            shutil.rmtree(self.options.cluster_base_dir)

    def restart(self):
        self.set_master_addresses()
        self.for_all_daemons(self.stop_daemon)
        self.for_all_daemons(self.start_daemon)
        self.modify_placement_info()

    def wipe_restart(self):
        num_servers_map = {DAEMON_TYPE_MASTER: self.get_number_of_servers(DAEMON_TYPE_MASTER),
                           DAEMON_TYPE_TSERVER: self.get_number_of_servers(DAEMON_TYPE_TSERVER)}
        self.set_master_addresses()
        self.destroy()
        self.start_helper(num_servers_map)
        self.modify_placement_info()

    def add_node(self):
        self.set_master_addresses(running_only=True)
        num_servers = self.get_number_of_servers(self.options.node_type)
        if len(self.options.placement_info) > 1:
            raise RuntimeError("Please specify exactly one placement_info value.")
        daemon_id = DaemonId(self.options.node_type, num_servers + 1)
        if self.options.node_type == DAEMON_TYPE_MASTER:
            self.options.is_shell_master = True
        self.start_daemon(daemon_id)
        self.change_config_if_master(daemon_id, "ADD_SERVER")

    def remove_node(self):
        # Note: remove_node in its current implementation just stops a node and does not
        # decommission it. To properly decommission a local "node", we'll need
        # to remove it from the master's metadata and also delete the data directory.
        daemon_id = DaemonId(self.options.node_type, self.args.node_id)
        logging.info("Stopping server {}".format(daemon_id))
        self.stop_daemon(daemon_id)

    def start_node(self):
        daemon_id = DaemonId(self.options.node_type, self.args.node_id)
        self.set_master_addresses()
        self.start_daemon(daemon_id)

    def stop_node(self):
        self.remove_node()

    def restart_node(self):
        daemon_id = DaemonId(self.options.node_type, self.args.node_id)
        self.stop_daemon(daemon_id)
        self.set_master_addresses()
        if len(self.options.placement_info) > 1:
            raise RuntimeError("Please specify exactly one placement_info value.")
        self.start_daemon(daemon_id)

    def status(self):
        self.for_all_daemons(self.show_node_status)

    def setup_redis(self):
        yb_admin_binary_path = self.options.get_binary_path("yb-admin")
        self.set_master_addresses()
        self.wait_for_cluster_or_raise()
        cmd_setup_redis_table = [yb_admin_binary_path,
                                 "--master_addresses",
                                 self.options.master_addresses,
                                 "--yb_num_shards_per_tserver",
                                 str(self.options.num_shards_per_tserver),
                                 "setup_redis_table"]
        proc = subprocess.Popen(
            cmd_setup_redis_table, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        result, _ = proc.communicate()
        if proc.returncode:
            print (result)
            raise RuntimeError("Failed to Setup Redis.")
        print ("Setup Redis successful.")

    def run_cluster_wide_postgres_initdb(self):
        initdb_binary_path = self.options.get_binary_path("initdb")

        logging.info("Running initdb to initialize PostgreSQL metadata in the YugaByte cluster")
        with SetAndRestoreEnv(
            {'FLAGS_pggate_master_addresses': self.options.master_addresses,
             'YB_ENABLED_IN_POSTGRES': '1'}):
            adjust_env_for_postgres()

            tmp_pg_data_dir = '/tmp/yb-ctl_tmp_pg_data_{}'.format(''.join(
                [random.choice('0123456789abcdef') for _ in range(32)]))

            try:
                subprocess.check_call([
                    initdb_binary_path,
                    '-D', tmp_pg_data_dir,
                    '-U', 'postgres'
                ])
            finally:
                if os.path.exists(tmp_pg_data_dir):
                    logging.info("Deleting temporary PostgreSQL data directory: %s",
                                 tmp_pg_data_dir)
                    shutil.rmtree(tmp_pg_data_dir, ignore_errors=True)

        logging.info(
            "Successfully ran initdb to initialize PostgreSQL data in the YugaByte cluster")

    # ---------------------------------------------------------------------------------------------
    # The "main" function of the ClusterControl class
    # ---------------------------------------------------------------------------------------------

    def run(self):
        self.args = self.parser.parse_args()
        self.options.update_options_from_args(self.args)

        # Load cluster configuration for the non-creation case -- however, we will override
        # this configuration if the command is "create".
        self.load_cluster_config()
        self.args.func()


if __name__ == "__main__":
    logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s %(levelname)s: %(message)s")

    try:
        ClusterControl().run()
    except ExitWithError, ex:
        logging.error(ex)
        sys.exit(1)
