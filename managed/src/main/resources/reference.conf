###########################################
#        Yugaware default configuration   #
###########################################
# You can override these in application.conf or through system properties.

# Install custom ObjectMapper
play.modules.disabled += "play.core.ObjectMapperModule"
play.modules.enabled  += "com.yugabyte.yw.common.CustomObjectMapperModule"

play.http.parser.maxDiskBuffer=100GB

akka {
  actor {
    default-dispatcher {
      type = "com.yugabyte.yw.common.logging.MDCPropagatingDispatcherConfigurator"
    }
  }
}

# ============= START DATABASE RELATED CONFIGURATION ==================================

# Lets disable the default play evolutions and use flyway db (overridden by yugabyted)
play.evolutions.enabled=false
# We use our own flyway initializer see: com.yugabyte.yw.common.ybflyway.PlayInitializer
# So we do not need to enable flyway-play module
# play.modules.enabled += "org.flywaydb.play.PlayModule"

db {
  # Tracking default postgresql connection details
  default {
    host="localhost"
    port=5432
    dbname="yugaware"
    username="postgres"
    username=${?DB_USERNAME}
    password=""
    password=${?DB_PASSWORD}
    driver="org.postgresql.Driver"
    url="jdbc:postgresql://"${db.default.host}":"${db.default.port}"/"${db.default.dbname}
    logStatements=true
    # Config about flyway migrations.
    migration {
      initOnMigrate=true
      auto=true
      ignoreMissingMigrations=true
      outOfOrder=true
      # We want to use postgres db in production
      # The migration scripts will be under resources/db.migration.default.postgres
      # with common scripts under resources/db.migration.default.common
      locations=["common","postgres"]
    }
  }
}
# =============  END DATABASE RELATED CONFIGURATION ==================================

ebean {
  default = ["com.yugabyte.yw.*"]
}

yb {
  mode="PLATFORM"
  use_kubectl=true
  universe_version_check_mode=NEVER  # possible values: NEVER, HA_ONLY, ALWAYS
  universe_boot_script = ""

  # Alerts thresholds
  alert {
    # Value of maximum allowed clock skew before an alert is generated (in ms).
    max_clock_skew_ms = 500
    # Value of maximum allowed replication lag before an alert is generated (in ms).
    replication_lag_ms = 180000
    # Value of maximum allowed percents of used memory on nodes.
    max_memory_cons_pct = 90
    # Alert rules configuration sync interval in seconds.
    config_sync_interval_sec = 60
    # Maximum allowed number of nodes with health check errors.
    health_check_nodes = 0
    # Maximum allowed number of nodes with inactive cronjob.
    inactive_cronjob_nodes = 0
    # For how long do we let the alert be in database after it has resolved
    resolved_retention_duration = 120 days
    # Value of average CPU usage which triggers warning alert
    max_cpu_usage_pct_warn = 90
    # Value of average CPU usage which triggers severe alert
    max_cpu_usage_pct_severe = 95
    # Value of node disk usage which triggers severe alert
    max_node_disk_usage_pct_severe = 70
    # Value of node file descriptors usage which triggers severe alert
    max_node_fd_usage_pct_severe = 70
    # Value of allowed OOM kills per 10 minutes before severe alert is triggered
    max_oom_kills_severe = 3
    # Value of allowed OOM kills per 10 minutes before warning alert is triggered
    max_oom_kills_warning = 1
    # Value of node certificate expiry in days which triggers severe alert
    max_node_cert_expiry_days_severe = 30
    # Value of encryption at rest config expiry in days which triggers severe alert
    max_enc_at_rest_config_expiry_days_severe = 3
    # Maximum average latency for YSQL operations
    max_ysql_opavg_latency = 10000
    # Maximum average latency for YCQL operations
    max_ycql_opavg_latency = 10000
    # Maximum P99 latency for YSQL operations
    max_ysql_p99_latency = 60000
    # Maximum P99 latency for YCQL operations
    max_ycql_p99_latency = 60000
    # Maximum number of YSQL connections
    max_ysql_connections = 300
    # Maximum number of YCQL connections
    max_ycql_connections = 1000
    # Maximum number of YEDIS connections
    max_yedis_connections = 1000
    # Maximum YSQL throughput
    max_ysql_throughput = 100000
    # Maximum YCQL throughput
    max_ycql_throughput = 100000
    # Underreplicated masters threshold which triggers severe alert
    underreplicated_masters_secs_severe = 900
    # Underreplicated tablet threshold which triggers severe alert
    underreplicated_tablets_secs_severe = 300
    # Leaderless tablet threshold which triggers severe alert
    leaderless_tablets_secs_severe = 300
  }
  # Used to skip certificates validation for the configure phase.
  # Possible values - ALL, HOSTNAME
  #(the latter is used for skipping validation of commonName and subjectAltName)
  tls.skip_cert_validation = ""
  commissioner {
    # initial and minimum number of threads used by commissioner
    core_threads = 50

    # max number of threads we will grow to if needed before starting to reject tasks
    max_threads = 200

    # duration for which thread pool will stay inflated before it shrinks back to core_threads
    thread_ttl = 1 minute

    # Frequency at which we check task progress
    progress_check_interval = 10 s

    # capacity of the thread pool queue
    queue_capacity = 1000
  }

  maintenance {
    # For how long do we let the maintenance window be in database after it has finished
    retention_duration = 1200 days
  }

  task {
    # initial and minimum number of threads used by each task
    core_threads = 1

    # max number of threads we will grow to if needed before starting to reject tasks
    max_threads = 10

    # duration for which thread pool will stay inflated before it shrinks back to core_threads
    thread_ttl = 1 minute

    # capacity of the thread pool queue
    queue_capacity = 1000

    # Whether overriding universe lock is allowed when force option is selected.
    # If it is disabled, force option will wait for the lock to be released.
    override_force_universe_lock = true

    # How long force lock should retry acquiring the universe's lock when
    # `override_force_universe_lock` is false. If no unit is selected, it will be in milliseconds.
    max_force_universe_lock_timeout = "1800s"
  }

  import {
    # initial and minimum number of threads used by import controller
    core_threads = 1

    # max number of threads we will grow to if needed before starting to reject tasks
    max_threads = 200

    # duration for which thread pool will stay inflated before it shrinks back to core_threads
    thread_ttl = 1 minute

    # capacity of the thread pool queue
    queue_capacity = 1000
  }

  # We delete completed task info form database.
  # Following config is for that task Garbage collection:
  taskGC {
    # How frequently do we check for completed tasks in database
    gc_check_interval = 1 days

    # For how long do we let the task be in database after it has completed
    task_retention_duration = 120 days
  }

  # Config for backup Garbage collection
  backupGC {
    # backup GC schedule run
    gc_run_interval = 15 minutes
  }

  aws {
    # default volume count for aws instance types with EBS Only storage info
    default_volume_count = 1

    # default volume size for aws instance types with EBS Only storage info
    default_volume_size_gb = 250

    storage {
      # GP3 free PIOPS
      gp3_free_piops = 3000

      # GP3 free throughput in MiB/sec
      gp3_free_throughput = 125
    }
  }

  pwdpolicy {
    default_min_length = 8
    default_min_uppercase = 1
    default_min_lowercase = 1
    default_min_digits = 1
    default_min_special_chars = 1
  }
  metrics {
    host="localhost"
    port="9090"
    url = "http://"${yb.metrics.host}":"${yb.metrics.port}"/api/v1"
    management.url = "http://"${yb.metrics.host}":"${yb.metrics.port}"/-"
    management.enabled = true
    db_read_write_test = true
    # Scrape target configuration sync interval in seconds.
    config_sync_interval_sec = 60
    scrape_interval = "10s"
    collection_level="NORMAL"
  }
  # sets logging level for file and stdout logs
  logging {
    config="DEBUG"
    rollover_pattern = "yyyy-MM-dd"
    max_history = "30"
    search_timeout_secs = "60"
    enable_task_failed_request_logs = true
  }
  storage.path="/opt/yugabyte"
  upgrade {
    #  Allow for leader blacklisting during universe upgrades
    blacklist_leaders = true
    blacklist_leader_wait_time_ms = 60000
    max_follower_lag_threshold_ms = 60000
    vmImage = ${yb.cloud.enabled}
  }
  releases {
      num_releases_to_keep_default = "3"
      num_releases_to_keep_cloud = "1"
  }
  ha {
    replication_schedule_enabled = false
    replication_frequency = 30 minutes
    prometheus_config_dir = "/prometheus_configs"
    num_backup_retention = 10
    logScriptOutput = false
    ws = ${play.ws}
    # Override this ws config in runtime_config at global level
    # Reference: https://github.com/playframework/play-ws/blob/main/play-ws-standalone/src/main/resources/reference.conf
    # Example:
#      {
#      ssl {
#         loose.acceptAnyCert = false
#         trustManager = {
#           stores += { # append to certs defined in play.ws
#               type = "PEM"
#               data = """-----BEGIN CERTIFICATE-----
# MIIDzTCCArWgAwIBAgIQCjeHZF5ftIwiTv0b7RQMPDANBgkqhkiG9w0BAQsFADBa
# ... You can use triple quoted string for multiline data ...
# -----END CERTIFICATE-----"""
#           }
#           stores += {
#             ... you can trust multiple certs ...
#           }
#        }
#      }
#    }
  }
  wait_for_server_timeout = 300000 ms
  # Timeout for proxy endpoint request of db node
  proxy_endpoint_timeout = 1 minute
  health {
    max_num_parallel_checks = 25
    max_num_parallel_node_checks = 50
    default_ssl = true
    default_tls = false
    # Email address to send alerts to at YugaByte.
    default_email = ""
    default_email = ${?YB_ALERTS_EMAIL}
    # Env vars used for SMTP authentication.
    ses_email_username = ""
    ses_email_username = ${?YB_ALERTS_USERNAME}
    ses_email_password = ""
    ses_email_password = ${?YB_ALERTS_PASSWORD}

    # Default SMTP server.
    default_smtp_server = "email-smtp.us-west-2.amazonaws.com"
    # And SMTP ports.
    default_smtp_port = 25
    default_smtp_port_ssl = 465
    debug_email = false

    # Default timeout for establishing the SMTP connection, in msec.
    smtp_connection_timeout_ms = 30000
    # Default timeout for sending the mail messages, in msec.
    smtp_timeout_ms = 60000

    # Interval at which to check the status of every universe. Default: 5 minutes.
    check_interval_ms = 300000
    # Interval at which to store the status of every universe in DB. Default: 5 minutes.
    store_interval_ms = 300000
    # Interval at which to send a status report email. Default: 12 hours.
    status_interval_ms = 43200000
    logOutput = false
  }

  security {
    enable_auth_for_proxy_metrics = true
    use_oauth = false
    use_oauth = ${?USE_OAUTH}
    type = ""
    type = ${?YB_SECURITY_TYPE}
    clientID = ""
    clientID = ${?YB_OIDC_CLIENT_ID}
    secret = ""
    secret = ${?YB_OIDC_SECRET}
    discoveryURI = ""
    discoveryURI = ${?YB_OIDC_DISCOVERY_URI}
    oidcScope = ""
    oidcScope = ${?YB_OIDC_SCOPE}
    oidcEmailAttribute = ""
    oidcEmailAttribute = ${?YB_OIDC_EMAIL_ATTR}
    ssh2_enabled = false
    ldap {
      use_ldap = "false"
      ldap_url = ""
      ldap_port = ""
      ldap_basedn = ""
      ldap_dn_prefix = "CN="
      ldap_customeruuid = ""
      ldap_service_account_username = ""
      ldap_service_account_password = ""
      enable_ldaps = false
      enable_ldap_start_tls = false
      use_search_and_bind = false
      ldap_search_attribute = ""
    }
  }

  ansible {

    # strategy can be linear, mitogen_linear or debug
    strategy = "linear"
    # https://docs.ansible.com/ansible/latest/reference_appendices/config.html#default-timeout
    conn_timeout_secs = 60

    # verbosity of ansible logs, 0 to 4 (more verbose)
    verbosity = 0
    # debug output (can include secrets in output)
    debug = false

    # https://docs.ansible.com/ansible/latest/reference_appendices/config.html#diff-always
    diff_always = false

    # https://docs.ansible.com/ansible/latest/reference_appendices/config.html#default-local-tmp
    local_temp = "/tmp/ansible_tmp/"

  }

  customer_task_db_query_limit = 2000
  cloud {
    enabled = false
    requestIdHeader = "X-REQUEST-ID"
  }

  internal {
    # AWS providers created while enabled will also have graviton instance types.
    graviton = false
    # Enabling removes supported instance type filtering on AWS providers.
    allow_unsupported_instances = false
    # Default AWS instance type
    default_aws_instance_type = "c5.4xlarge"
  }

  dbmem {
    postgres {
      max_mem_mb = 0
    }

    checks {
      # Used in checking memAvailable.
      mem_available_limit_kb = 716800
    }
  }

  backup {
    pg_based = false
    enable_sse = false
  }

  logs {
    cmdOutputDelete = true
    max_msg_size = 2M
  }

  audit {
    log {
      # Used in AuditAction to enable audit logging checks
      verifyLogging = false
      outputToStdout = false
      outputToFile = true
      rolloverPattern = "yyyy-MM-dd"
      maxHistory = "30"
    }
  }

  support_bundle {
    # default N days of logs to get if no dates specified
    default_date_range = 7
    application_logs_regex_pattern = "application-log-\\d{4}-\\d{2}-\\d{2}\\.gz"
    application_logs_sdf_pattern = "'application-log-'yyyy-MM-dd'.gz'"
    k8s_mount_point_prefix = "/mnt/disk"
    default_mount_point_prefix = "/mnt/d"
    universe_logs_regex_pattern = "(?:(?:.*)(?:yb-)(?:master|tserver)(?:.*)(\\d{8})-(?:\\d*)\\.(?:.*))|(?:(?:.*)(?:postgresql)-(.{10})(?:.*))"
    retention_days = 10
    k8s_enabled = true
    onprem_enabled = true
  }
  # certificate issued would be with expiry of following
  tlsCertificate.expiryInYears = 4

  # TODO(vipulbansal) start using this now that setting objects is allowed
  external_script {
    content = ""
    params = ""
    schedule = ""
  }

  query_stats {
    excluded_queries = [
      "SET extra_float_digits = 3"
    ]
    slow_queries {
       limit = 50
       # Descending sort possible values: total_time, max_time, mean_time, rows, calls
       # columns of pg_stat_statements view
       # See https://www.postgresql.org/docs/current/pgstatstatements.html#id-1.11.7.39.6
       order_by = "total_time"
    }
    # initial and minimum number of threads used by import controller
    core_threads = 1

    # max number of threads we will grow to if needed before starting to reject tasks
    max_threads = 50

    # duration for which thread pool will stay inflated before it shrinks back to core_threads
    thread_ttl = 1 minute

    # capacity of the thread pool queue
    queue_capacity = 500
  }

  gflags {
    notify_peer_of_removal_from_cluster = false
  }

}

ybc {
  timeout {
    admin_operation_timeout_ms = 120000
    socket_read_timeout_ms = 30000
    operation_timeout_ms = 60000
  }
}

runtime_config {
  included_objects = [
    "yb.external_script"
    "yb.ha.ws"
  ]
  included_paths = [
      #  We can set this to "yb." if/when there are more includedPaths than excludedPaths
      "yb.taskGC."
      "yb.backupGC."
      "yb.alert.max_clock_skew_ms"
      "yb.customer_task_db_query_limit"
      "yb.proxy_endpoint_timeout"
      "yb.cloud.enabled" # should be excluded for cloud deployments
      "yb.universe_boot_script"
      "yb.health.logOutput"
      "yb.health.max_num_parallel_node_checks"
      "yb.ha.logScriptOutput"
      "yb.internal.",
      "yb.ansible.",
      "yb.upgrade.",
      "yb.releases.",
      "yb.tls.skip_cert_validation",
      "yb.dbmem.",
      "yb.security.ldap.",
      "yb.use_kubectl",
      "yb.security.use_oauth",
      "yb.security.type",
      "yb.security.clientID",
      "yb.security.secret",
      "yb.security.discoveryURI",
      "yb.security.oidcScope",
      "yb.security.oidcEmailAttribute",
      "yb.security.ssh2_enabled"
      "yb.backup.pg_based",
      "yb.backup.enable_sse",
      "yb.logs.",
      "yb.audit.",
      "yb.metrics.db_read_write_test",
      "yb.metrics.collection_level",
      "yb.support_bundle.k8s_enabled",
      "yb.support_bundle.onprem_enabled",
      "yb.internal.allow_unsupported_instances",
      "yb.universe_version_check_mode",
      "yb.query_stats."
      "ybc.timeout",
      "yb.gflags.notify_peer_of_removal_from_cluster"
  ]
  excluded_paths = [
  ]
}

kamon.prometheus {
  embedded-server {
    hostname = "localhost"
    port = 9095
  }
}
