-- Split at 1, ... to ensure that the value r1 = 1 is present in more than one tablet.
-- See #18101.
CREATE TABLE t(r1 INT, r2 INT, r3 INT, v INT, PRIMARY KEY(r1 ASC, r2 ASC, r3 ASC)) SPLIT AT VALUES ((1, 1, 500));
INSERT INTO t (SELECT 1, i%3, i, i/3 FROM GENERATE_SERIES(1, 1000) AS i);
-- Add one more distinct value to catch bugs that arise only with more than one distinct value.
INSERT INTO t (SELECT 2, i%3, i, i/3 FROM GENERATE_SERIES(1, 1000) AS i);
-- Test the flag.
SET yb_enable_distinct_pushdown TO off;
-- Do not pick Distinct Index Scan since the flag is off.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1 FROM t;
                   QUERY PLAN
------------------------------------------------
 HashAggregate (actual rows=2 loops=1)
   Group Key: r1
   ->  Seq Scan on t (actual rows=2000 loops=1)
(3 rows)

-- XXX: Results may not be consistent (no explicit ordering).
SELECT DISTINCT r1 FROM t;
 r1
----
  2
  1
(2 rows)

-- Turn the flag back on.
SET yb_enable_distinct_pushdown TO on;
-- Pick Distinct Index Scan.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1 FROM t;
                             QUERY PLAN
---------------------------------------------------------------------
 Unique (actual rows=2 loops=1)
   ->  Distinct Index Scan using t_pkey on t (actual rows=3 loops=1)
         Distinct Keys: r1
(3 rows)

SELECT DISTINCT r1 FROM t;
 r1
----
  1
  2
(2 rows)

-- Test a larger prefix.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, r2 FROM t;
                             QUERY PLAN
---------------------------------------------------------------------
 Unique (actual rows=6 loops=1)
   ->  Distinct Index Scan using t_pkey on t (actual rows=7 loops=1)
         Distinct Keys: r1, r2
(3 rows)

SELECT DISTINCT r1, r2 FROM t;
 r1 | r2
----+----
  1 |  0
  1 |  1
  1 |  2
  2 |  0
  2 |  1
  2 |  2
(6 rows)

-- Even though the index scan does not return distinct values of r2, using
--   a Distinct Index Scan can still help retrieve fewer rows from storage.
-- Observe that this behavior deviates from ORDER BY where partial sorts
--   are not useful but partial DISTINCT scans are still worth it.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r2 FROM t;
                             QUERY PLAN
---------------------------------------------------------------------
 HashAggregate (actual rows=3 loops=1)
   Group Key: r2
   ->  Distinct Index Scan using t_pkey on t (actual rows=7 loops=1)
         Distinct Keys: r1, r2
(4 rows)

SELECT DISTINCT r2 FROM t;
 r2
----
  0
  2
  1
(3 rows)

-- Limit clauses.
-- Limit goes after DISTINCT (this includes the Unique node).
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1 FROM t LIMIT 2;
                                QUERY PLAN
---------------------------------------------------------------------------
 Limit (actual rows=2 loops=1)
   ->  Unique (actual rows=2 loops=1)
         ->  Distinct Index Scan using t_pkey on t (actual rows=3 loops=1)
               Distinct Keys: r1
(4 rows)

SELECT DISTINCT r1 FROM t LIMIT 2;
 r1
----
  1
  2
(2 rows)

-- Now, test other data types.
-- Test floating point data.
CREATE TABLE tr(r1 REAL, r2 REAL, PRIMARY KEY(r1 ASC, r2 ASC));
INSERT INTO tr (SELECT 0.5, i FROM GENERATE_SERIES(1, 1000) AS i);
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1 FROM tr;
                              QUERY PLAN
-----------------------------------------------------------------------
 Unique (actual rows=1 loops=1)
   ->  Distinct Index Scan using tr_pkey on tr (actual rows=1 loops=1)
         Distinct Keys: r1
(3 rows)

SELECT DISTINCT r1 FROM tr;
 r1
-----
 0.5
(1 row)

DROP TABLE tr;
-- Test text data as well.
CREATE TABLE ts(r1 TEXT, r2 TEXT, v TEXT, PRIMARY KEY(r1 ASC, r2 ASC));
INSERT INTO ts (SELECT 'uniq', i::TEXT, 'value' FROM GENERATE_SERIES(1, 1000) AS i);
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1 FROM ts;
                              QUERY PLAN
-----------------------------------------------------------------------
 Unique (actual rows=1 loops=1)
   ->  Distinct Index Scan using ts_pkey on ts (actual rows=1 loops=1)
         Distinct Keys: r1
(3 rows)

SELECT DISTINCT r1 FROM ts;
  r1
------
 uniq
(1 row)

DROP TABLE ts;
-- Ensure that Distinct Index Scan is not generated for a non-LSM index.
-- Non-LSM indexes such as GIN do not necessarily support distinct index scan.
CREATE TABLE vectors (v tsvector, k SERIAL PRIMARY KEY);
INSERT INTO vectors SELECT to_tsvector('simple', 'filler') FROM generate_series(1, 10);
CREATE INDEX NONCONCURRENTLY igin ON vectors USING ybgin (v);
-- Avoid fetching primary key and fetch secondary key instead since
--   there is already an LSM index on the primary key and LSM supports distinct index scan.
SET yb_explain_hide_non_deterministic_fields = true;
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT v FROM vectors;
                        QUERY PLAN
----------------------------------------------------------
 Unique (actual rows=1 loops=1)
   ->  Sort (actual rows=10 loops=1)
         Sort Key: v
         Sort Method: quicksort
         ->  Seq Scan on vectors (actual rows=10 loops=1)
(5 rows)

SELECT DISTINCT v FROM vectors;
     v
------------
 'filler':1
(1 row)

DROP INDEX igin;
DROP TABLE vectors;
-- Test distinct index scans in scenarios where user provides explicit ordering.
-- Start off easy with forward and backward scans.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1 FROM t ORDER BY r1;
                             QUERY PLAN
---------------------------------------------------------------------
 Unique (actual rows=2 loops=1)
   ->  Distinct Index Scan using t_pkey on t (actual rows=3 loops=1)
         Distinct Keys: r1
(3 rows)

SELECT DISTINCT r1 FROM t ORDER BY r1;
 r1
----
  1
  2
(2 rows)

EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1 FROM t ORDER BY r1 DESC;
                                  QUERY PLAN
------------------------------------------------------------------------------
 Unique (actual rows=2 loops=1)
   ->  Distinct Index Scan Backward using t_pkey on t (actual rows=3 loops=1)
         Distinct Keys: r1
(3 rows)

SELECT DISTINCT r1 FROM t ORDER BY r1 DESC;
 r1
----
  2
  1
(2 rows)

-- Now, try a larger prefix.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, r2 FROM t ORDER BY r1, r2;
                             QUERY PLAN
---------------------------------------------------------------------
 Unique (actual rows=6 loops=1)
   ->  Distinct Index Scan using t_pkey on t (actual rows=7 loops=1)
         Distinct Keys: r1, r2
(3 rows)

SELECT DISTINCT r1, r2 FROM t ORDER BY r1, r2;
 r1 | r2
----+----
  1 |  0
  1 |  1
  1 |  2
  2 |  0
  2 |  1
  2 |  2
(6 rows)

EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, r2 FROM t ORDER BY r1 DESC, r2 DESC;
                                  QUERY PLAN
------------------------------------------------------------------------------
 Unique (actual rows=6 loops=1)
   ->  Distinct Index Scan Backward using t_pkey on t (actual rows=7 loops=1)
         Distinct Keys: r1, r2
(3 rows)

SELECT DISTINCT r1, r2 FROM t ORDER BY r1 DESC, r2 DESC;
 r1 | r2
----+----
  2 |  2
  2 |  1
  2 |  0
  1 |  2
  1 |  1
  1 |  0
(6 rows)

-- Now, we try only a subset of the prefix.
-- Picking a Distinct Index Scan for such cases can still be useful since
--   the storage layer retrieves and returns fewer rows overall.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, r2 FROM t ORDER BY r2;
                                QUERY PLAN
---------------------------------------------------------------------------
 Sort (actual rows=6 loops=1)
   Sort Key: r2
   Sort Method: quicksort
   ->  Unique (actual rows=6 loops=1)
         ->  Distinct Index Scan using t_pkey on t (actual rows=7 loops=1)
               Distinct Keys: r1, r2
(6 rows)

SELECT DISTINCT r1, r2 FROM t ORDER BY r2;
 r1 | r2
----+----
  1 |  0
  2 |  0
  1 |  1
  2 |  1
  1 |  2
  2 |  2
(6 rows)

-- m in tm refers to mixed ordering.
-- Sort order does not matter when distinct-ifying the columns.
-- Hence, generate Distinct Index Scans even for keys with a mix of
--   ascending and descending orders in the LSM index.
CREATE TABLE tm(r1 INT, r2 INT, r3 INT, v INT, PRIMARY KEY(r1 DESC, r2 ASC, r3 ASC));
INSERT INTO tm (SELECT i%3, 2-i%3, i, i/3 FROM GENERATE_SERIES(1, 1000) AS i);
-- Test both forward and backwards scans.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, r2 FROM tm;
                              QUERY PLAN
-----------------------------------------------------------------------
 Unique (actual rows=3 loops=1)
   ->  Distinct Index Scan using tm_pkey on tm (actual rows=3 loops=1)
         Distinct Keys: r1, r2
(3 rows)

SELECT DISTINCT r1, r2 FROM tm;
 r1 | r2
----+----
  2 |  0
  1 |  1
  0 |  2
(3 rows)

-- This is a backwards scan because of how the keys are ordered in the primary index.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, r2 FROM tm ORDER BY r1, r2 DESC;
                                   QUERY PLAN
--------------------------------------------------------------------------------
 Unique (actual rows=3 loops=1)
   ->  Distinct Index Scan Backward using tm_pkey on tm (actual rows=3 loops=1)
         Distinct Keys: r1, r2
(3 rows)

SELECT DISTINCT r1, r2 FROM tm ORDER BY r1, r2 DESC;
 r1 | r2
----+----
  0 |  2
  1 |  1
  2 |  0
(3 rows)

DROP TABLE tm;
-- Aggregates.
-- Unless the aggregate is pushed down into distinct index scan,
-- cannot currently push down DISTINCT.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, COUNT(r1) FROM t GROUP BY r1;
                      QUERY PLAN
------------------------------------------------------
 HashAggregate (actual rows=2 loops=1)
   Group Key: r1, count(r1)
   ->  HashAggregate (actual rows=2 loops=1)
         Group Key: r1
         ->  Seq Scan on t (actual rows=2000 loops=1)
(5 rows)

SELECT DISTINCT r1, COUNT(r1) FROM t GROUP BY r1;
 r1 | count
----+-------
  1 |  1000
  2 |  1000
(2 rows)

-- Window Funcs.
-- Same reasoning applies to window funcs as well.
EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF, SUMMARY OFF) SELECT DISTINCT r1, COUNT(r1) OVER (PARTITION BY r1) FROM t;
                             QUERY PLAN
---------------------------------------------------------------------
 HashAggregate (actual rows=2 loops=1)
   Group Key: r1, count(r1) OVER (?)
   ->  WindowAgg (actual rows=2000 loops=1)
         ->  Index Scan using t_pkey on t (actual rows=2000 loops=1)
(4 rows)

SELECT DISTINCT r1, COUNT(r1) OVER (PARTITION BY r1) FROM t;
 r1 | count
----+-------
  1 |  1000
  2 |  1000
(2 rows)

SELECT DISTINCT r1 FROM t WHERE r1 = 1 AND r2 IN (0, 1);
 r1
----
  1
(1 row)

-- DISTINCT ON query for regression purposes.
SELECT DISTINCT ON (r1) r1, r2 FROM t ORDER BY r1, r2;
 r1 | r2
----+----
  1 |  0
  2 |  0
(2 rows)

DROP TABLE t;
