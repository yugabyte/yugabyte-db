SET search_path TO documentdb_core,documentdb_api,documentdb_api_catalog,documentdb_api_internal;
SET citus.next_shard_id TO 662000;
SET documentdb.next_collection_id TO 6620;
SET documentdb.next_collection_index_id TO 6620;
CREATE SCHEMA bulk_write;
SELECT documentdb_api.create_collection('db', 'write_batching');
NOTICE:  creating collection
 create_collection 
---------------------------------------------------------------------
 t
(1 row)

CREATE FUNCTION bulk_write.do_bulk_insert(numIterations int, ordered bool)
RETURNS bson
SET search_path TO documentdb_core,documentdb_api_catalog, pg_catalog
AS $fn$
DECLARE
    v_insertSpec bson;
    v_resultDocs bson;
BEGIN

WITH r1 AS ( SELECT array_agg(FORMAT('{ "_id": %s, "a": %s}', g, g)::bson) AS "documents" FROM generate_series(1, numIterations) g),
    r2 AS (SELECT 'write_batching' AS "insert", r1.documents AS "documents", ordered AS "ordered" FROM r1)
    SELECT row_get_bson(r2) INTO v_insertSpec FROM r2;

    SELECT p_result INTO v_resultDocs FROM documentdb_api.insert('db', v_insertSpec);
    RETURN v_resultDocs;
END;
$fn$ LANGUAGE plpgsql;
CREATE FUNCTION bulk_write.do_bulk_update(numIterations int, ordered bool)
RETURNS bson
SET search_path TO documentdb_core,documentdb_api_catalog, pg_catalog
AS $fn$
DECLARE
    v_updateSpec bson;
    v_resultDocs bson;
BEGIN

WITH r1 AS ( SELECT array_agg(FORMAT('{ "q": { "_id": %s}, "u": { "$inc": { "a": 1 } } }', MOD(g, 10) + 1)::bson) AS "documents" FROM generate_series(1, numIterations) g),
    r2 AS (SELECT 'write_batching' AS "update", r1.documents AS "updates", ordered AS "ordered" FROM r1)
    SELECT row_get_bson(r2) INTO v_updateSpec FROM r2;

    SELECT p_result INTO v_resultDocs FROM documentdb_api.update('db', v_updateSpec);
    RETURN v_resultDocs;
END;
$fn$ LANGUAGE plpgsql;
-- try a small amount.
BEGIN;
SELECT bulk_write.do_bulk_insert(10, false);
                            do_bulk_insert                             
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "10" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

ROLLBACK;
-- try an extremely large batch (maxBatchSize)
BEGIN;
SELECT bulk_write.do_bulk_insert(25000, false);
                              do_bulk_insert                              
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "25000" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

ROLLBACK;
-- try an extremely large batch (maxBatchSize + 1 ) fails
BEGIN;
SELECT bulk_write.do_bulk_insert(25001, false);
ERROR:  Write batch sizes must be between 1 and 25000. Got 25001 operations.
CONTEXT:  SQL statement "SELECT p_result                   FROM documentdb_api.insert('db', v_insertSpec)"
PL/pgSQL function bulk_write.do_bulk_insert(integer,boolean) line 11 at SQL statement
ROLLBACK;
BEGIN;
SELECT bulk_write.do_bulk_insert(25001, true);
ERROR:  Write batch sizes must be between 1 and 25000. Got 25001 operations.
CONTEXT:  SQL statement "SELECT p_result                   FROM documentdb_api.insert('db', v_insertSpec)"
PL/pgSQL function bulk_write.do_bulk_insert(integer,boolean) line 11 at SQL statement
ROLLBACK;
-- introduce a failure in the 432'th position (Everything before that succeeds)
BEGIN;
SELECT documentdb_api.insert_one('db', 'write_batching', '{ "_id": 432, "a": 600 }');
                              insert_one                              
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "1" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

SELECT bulk_write.do_bulk_insert(5000, true);
                                                                                                                       do_bulk_insert                                                                                                                        
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "431" }, "ok" : { "$numberDouble" : "1.0" }, "writeErrors" : [ { "index" : { "$numberInt" : "431" }, "code" : { "$numberInt" : "319029277" }, "errmsg" : "Duplicate key violation on the requested collection: Index '_id_'" } ] }
(1 row)

SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching');
 count 
---------------------------------------------------------------------
   432
(1 row)

ROLLBACK;
-- introduce a failure in the 432'th position (Everything except that succeeds)
BEGIN;
SELECT documentdb_api.insert_one('db', 'write_batching', '{ "_id": 432, "a": 600 }');
                              insert_one                              
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "1" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

SELECT bulk_write.do_bulk_insert(5000, false);
                                                                                                                        do_bulk_insert                                                                                                                        
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "4999" }, "ok" : { "$numberDouble" : "1.0" }, "writeErrors" : [ { "index" : { "$numberInt" : "431" }, "code" : { "$numberInt" : "319029277" }, "errmsg" : "Duplicate key violation on the requested collection: Index '_id_'" } ] }
(1 row)

SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching');
 count 
---------------------------------------------------------------------
  5000
(1 row)

ROLLBACK;
BEGIN;
set local documentdb.batchWriteSubTransactionCount TO 40;
SELECT documentdb_api.insert_one('db', 'write_batching', '{ "_id": 31, "a": 600 }');
                              insert_one                              
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "1" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

SELECT bulk_write.do_bulk_insert(35, false);
                                                                                                                      do_bulk_insert                                                                                                                       
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "34" }, "ok" : { "$numberDouble" : "1.0" }, "writeErrors" : [ { "index" : { "$numberInt" : "30" }, "code" : { "$numberInt" : "319029277" }, "errmsg" : "Duplicate key violation on the requested collection: Index '_id_'" } ] }
(1 row)

SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching');
 count 
---------------------------------------------------------------------
    35
(1 row)

ROLLBACK;
BEGIN;
set local documentdb.batchWriteSubTransactionCount TO 40;
SELECT documentdb_api.insert_one('db', 'write_batching', '{ "_id": 31, "a": 600 }');
                              insert_one                              
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "1" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

SELECT bulk_write.do_bulk_insert(39, false);
                                                                                                                      do_bulk_insert                                                                                                                       
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "38" }, "ok" : { "$numberDouble" : "1.0" }, "writeErrors" : [ { "index" : { "$numberInt" : "30" }, "code" : { "$numberInt" : "319029277" }, "errmsg" : "Duplicate key violation on the requested collection: Index '_id_'" } ] }
(1 row)

SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching');
 count 
---------------------------------------------------------------------
    39
(1 row)

ROLLBACK;
BEGIN;
set local documentdb.batchWriteSubTransactionCount TO 40;
SELECT documentdb_api.insert_one('db', 'write_batching', '{ "_id": 31, "a": 600 }');
                              insert_one                              
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "1" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

SELECT bulk_write.do_bulk_insert(40, false);
                                                                                                                      do_bulk_insert                                                                                                                       
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "39" }, "ok" : { "$numberDouble" : "1.0" }, "writeErrors" : [ { "index" : { "$numberInt" : "30" }, "code" : { "$numberInt" : "319029277" }, "errmsg" : "Duplicate key violation on the requested collection: Index '_id_'" } ] }
(1 row)

SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching');
 count 
---------------------------------------------------------------------
    40
(1 row)

ROLLBACK;
BEGIN;
set local documentdb.batchWriteSubTransactionCount TO 40;
SELECT documentdb_api.insert_one('db', 'write_batching', '{ "_id": 31, "a": 600 }');
                              insert_one                              
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "1" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

SELECT bulk_write.do_bulk_insert(41, false);
                                                                                                                      do_bulk_insert                                                                                                                       
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "40" }, "ok" : { "$numberDouble" : "1.0" }, "writeErrors" : [ { "index" : { "$numberInt" : "30" }, "code" : { "$numberInt" : "319029277" }, "errmsg" : "Duplicate key violation on the requested collection: Index '_id_'" } ] }
(1 row)

SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching');
 count 
---------------------------------------------------------------------
    41
(1 row)

ROLLBACK;
-- now insert 10 docs and commit
SELECT bulk_write.do_bulk_insert(10, false);
                            do_bulk_insert                             
---------------------------------------------------------------------
 { "n" : { "$numberInt" : "10" }, "ok" : { "$numberDouble" : "1.0" } }
(1 row)

-- do a small bulk update
BEGIN;
SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching') WHERE document->'_id' = document->'a';
 count 
---------------------------------------------------------------------
    10
(1 row)

SELECT bulk_write.do_bulk_update(10, false);
                                                 do_bulk_update                                                 
---------------------------------------------------------------------
 { "ok" : { "$numberDouble" : "1.0" }, "nModified" : { "$numberLong" : "10" }, "n" : { "$numberLong" : "10" } }
(1 row)

SELECT COUNT(*) FROM documentdb_api.collection('db', 'write_batching') WHERE document->'_id' = document->'a';
 count 
---------------------------------------------------------------------
     0
(1 row)

ROLLBACK;
BEGIN;
SELECT bulk_write.do_bulk_update(10, true);
                                                 do_bulk_update                                                 
---------------------------------------------------------------------
 { "ok" : { "$numberDouble" : "1.0" }, "nModified" : { "$numberLong" : "10" }, "n" : { "$numberLong" : "10" } }
(1 row)

ROLLBACK;
BEGIN;
-- do a large number (fail)
SELECT bulk_write.do_bulk_update(25001, false);
ERROR:  Write batch sizes must be between 1 and 25000. Got 25001 operations.
CONTEXT:  SQL statement " SELECT documentdb_api_internal.update_worker($1, $2, $3, $4::documentdb_core.bson, $5::documentdb_core.bsonsequence, $6) FROM documentdb_data.documents_6620 WHERE shard_key_value = 6620"
SQL statement "SELECT p_result                   FROM documentdb_api.update('db', v_updateSpec)"
PL/pgSQL function bulk_write.do_bulk_update(integer,boolean) line 11 at SQL statement
ROLLBACK;
BEGIN;
-- do a large number (fail)
SELECT bulk_write.do_bulk_update(25001, true);
ERROR:  Write batch sizes must be between 1 and 25000. Got 25001 operations.
CONTEXT:  SQL statement " SELECT documentdb_api_internal.update_worker($1, $2, $3, $4::documentdb_core.bson, $5::documentdb_core.bsonsequence, $6) FROM documentdb_data.documents_6620 WHERE shard_key_value = 6620"
SQL statement "SELECT p_result                   FROM documentdb_api.update('db', v_updateSpec)"
PL/pgSQL function bulk_write.do_bulk_update(integer,boolean) line 11 at SQL statement
ROLLBACK;
BEGIN;
-- do a large number
SELECT bulk_write.do_bulk_update(10000, false);
                                                    do_bulk_update                                                    
---------------------------------------------------------------------
 { "ok" : { "$numberDouble" : "1.0" }, "nModified" : { "$numberLong" : "10000" }, "n" : { "$numberLong" : "10000" } }
(1 row)

ROLLBACK;
-- introduce an error in one document
BEGIN;
SELECT documentdb_api.update('db', '{ "update": "write_batching", "updates": [{ "q": { "_id": 5 }, "u": { "$set": { "a": "this is a string" } } }] }');
                                                                update                                                                
---------------------------------------------------------------------
 ("{ ""ok"" : { ""$numberDouble"" : ""1.0"" }, ""nModified"" : { ""$numberLong"" : ""1"" }, ""n"" : { ""$numberLong"" : ""1"" } }",t)
(1 row)

set local documentdb.batchWriteSubTransactionCount TO 40;
SELECT bulk_write.do_bulk_update(50, false);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            do_bulk_update                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
---------------------------------------------------------------------
 { "ok" : { "$numberDouble" : "1.0" }, "nModified" : { "$numberLong" : "45" }, "n" : { "$numberLong" : "45" }, "writeErrors" : [ { "index" : { "$numberInt" : "3" }, "code" : { "$numberInt" : "67108893" }, "errmsg" : "Cannot apply $inc to a value of non-numeric type. { _id: 5 } has the field 'a' of non-numeric type string" }, { "index" : { "$numberInt" : "13" }, "code" : { "$numberInt" : "67108893" }, "errmsg" : "Cannot apply $inc to a value of non-numeric type. { _id: 5 } has the field 'a' of non-numeric type string" }, { "index" : { "$numberInt" : "23" }, "code" : { "$numberInt" : "67108893" }, "errmsg" : "Cannot apply $inc to a value of non-numeric type. { _id: 5 } has the field 'a' of non-numeric type string" }, { "index" : { "$numberInt" : "33" }, "code" : { "$numberInt" : "67108893" }, "errmsg" : "Cannot apply $inc to a value of non-numeric type. { _id: 5 } has the field 'a' of non-numeric type string" }, { "index" : { "$numberInt" : "43" }, "code" : { "$numberInt" : "67108893" }, "errmsg" : "Cannot apply $inc to a value of non-numeric type. { _id: 5 } has the field 'a' of non-numeric type string" } ] }
(1 row)

ROLLBACK;
