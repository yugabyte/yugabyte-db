//  Copyright (c) 2011-present, Facebook, Inc.  All rights reserved.
//  This source code is licensed under the BSD-style license found in the
//  LICENSE file in the root directory of this source tree. An additional grant
//  of patent rights can be found in the PATENTS file in the same directory.
//
// The following only applies to changes made to this file as part of YugaByte development.
//
// Portions Copyright (c) YugaByte, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
// in compliance with the License.  You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software distributed under the License
// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
// or implied.  See the License for the specific language governing permissions and limitations
// under the License.
//
// Copyright (c) 2011 The LevelDB Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file. See the AUTHORS file for names of contributors.
//
// Decodes the blocks generated by block_builder.cc.

#include "yb/rocksdb/table/block.h"

#include <algorithm>
#include <string>
#include <unordered_map>
#include <vector>

#include "yb/util/logging.h"

#include "yb/rocksdb/comparator.h"
#include "yb/rocksdb/table/block_hash_index.h"
#include "yb/rocksdb/table/block_internal.h"
#include "yb/rocksdb/table/block_prefix_index.h"
#include "yb/rocksdb/table/format.h"
#include "yb/rocksdb/util/coding.h"
#include "yb/rocksdb/util/perf_context_imp.h"

#include "yb/util/result.h"
#include "yb/util/stats/perf_step_timer.h"

namespace rocksdb {

namespace {

// Empty block consists of (see comments inside block_builder.cc for block structure):
// - 0 data keys
// - uint32 for single restart point (first restart point is always 0 and present in block)
// - num_restarts: uint32
const size_t kMinBlockSize = 2 * sizeof(uint32_t);

inline uint32_t GetMiddleIndex(
    const uint32_t total_number, const MiddlePointPolicy middle_point_policy) {
  return total_number ? (total_number - yb::to_underlying(middle_point_policy)) / 2 : 0;
}

// Helper routine: decode the next block entry starting at "p",
// storing the number of shared key bytes, non_shared key bytes,
// and the length of the value in "*shared", "*non_shared", and
// "*value_length", respectively.  Will not derefence past "limit".
//
// If any errors are detected, returns nullptr.  Otherwise, returns a
// pointer to the key delta (just past the three decoded values).
inline const char* DecodeEntry(const char* p, const char* limit,
                               uint32_t* shared,
                               uint32_t* non_shared,
                               uint32_t* value_length) {
  if (limit - p < 3) return nullptr;
  *shared = reinterpret_cast<const unsigned char*>(p)[0];
  *non_shared = reinterpret_cast<const unsigned char*>(p)[1];
  *value_length = reinterpret_cast<const unsigned char*>(p)[2];
  if ((*shared | *non_shared | *value_length) < 128) {
    // Fast path: all three values are encoded in one byte each
    p += 3;
  } else {
    if ((p = GetVarint32Ptr(p, limit, shared)) == nullptr) return nullptr;
    if ((p = GetVarint32Ptr(p, limit, non_shared)) == nullptr) return nullptr;
    if ((p = GetVarint32Ptr(p, limit, value_length)) == nullptr) return nullptr;
  }

  if (static_cast<uint32_t>(limit - p) < (*non_shared + *value_length)) {
    return nullptr;
  }
  return p;
}

// Decodes restart key size (key_size) and value size (value_size) starting at `p` and returns
// pointer to the next byte after decoded data. Expects restart key to be stored fully without
// reusing bytes from previous key (see BlockBuilder::Add for more details).
// This function should not read at or beyond `limit`.
// Returns nullptr in case of decode failure.
inline const char* DecodeRestartEntry(
    const KeyValueEncodingFormat key_value_encoding_format, const char* p, const char* limit,
    const char* read_allowed_from, uint32_t* key_size) {
  uint32_t value_size;
  switch (key_value_encoding_format) {
    case KeyValueEncodingFormat::kKeyDeltaEncodingSharedPrefix: {
      uint32_t shared_prefix_size;
      auto* result = DecodeEntry(p, limit, &shared_prefix_size, key_size, &value_size);
      return result && (shared_prefix_size == 0) ? result : nullptr;
    }
    case KeyValueEncodingFormat::kKeyDeltaEncodingThreeSharedParts: {
      // We declare output variables for DecodeEntryThreeSharedParts, but since we are
      // decoding restart key and it is stored fully - we are only interested in non_shared_1_size
      // argument that stores full key size in this case (see BlockBuilder::Add for more details).
      // So, we just pass key_size as non_shared_1_size to DecodeEntryThreeSharedParts.
      uint32_t shared_prefix_size, non_shared_2_size, shared_last_component_size;
      bool is_something_shared;
      int64_t non_shared_1_size_delta, non_shared_2_size_delta;
      uint64_t shared_last_component_increase;

      auto* result = DecodeEntryThreeSharedParts(
          p, limit, &shared_prefix_size, key_size, &non_shared_1_size_delta,
          &is_something_shared, &non_shared_2_size, &non_shared_2_size_delta,
          &shared_last_component_size, &shared_last_component_increase, &value_size);
      if (PREDICT_FALSE(!result || is_something_shared)) {
        // This means corruption or decode failure, restart key is stored fully without reusing any
        // data from the previous key.
        return nullptr;
      }
      return result;
    }
  }
  FATAL_INVALID_ENUM_VALUE(KeyValueEncodingFormat, key_value_encoding_format);
}

} // namespace

const KeyValueEntry& BlockIter::Next() {
  DCHECK(Valid());
  ParseNextKey();
  return Entry();
}

const KeyValueEntry& BlockIter::Prev() {
  DCHECK(Valid());

  const auto current_offset = current_;

  // Try to move to the previous entry if it is cached.
  if (block_entry_cache_idx_ > 0) {
    --block_entry_cache_idx_;
    // Restoring current entry offset invariant.
    if (block_entry_cache_idx_ == 0) {
      current_ = GetRestartBlockOffset(restart_index_);
    } else {
      const auto& entry = block_entry_cache_[block_entry_cache_idx_ - 1].entry_;
      DCHECK(entry.Valid()) << "at " << block_entry_cache_idx_ - 1;
      current_ = static_cast<uint32_t>(entry.value.cend() - data_);
    }
    return Entry();
  }

  // Scan backwards to a restart point before current restart block.
  while (GetRestartBlockOffset(restart_index_) >= current_offset) {
    if (restart_index_) {
      --restart_index_;
      continue;
    }

    // No more entries.
    SetInvalid();
    return Entry();
  }

  MoveToRestartBlock(restart_index_);
  do {
    // Loop until end of current entry hits the start of original entry
  } while (ParseNextKey() && NextEntryOffset() < current_offset);
  return Entry();
}

void BlockIter::Initialize(
    const Comparator* comparator, const char* data,
    const KeyValueEncodingFormat key_value_encoding_format,
    const uint32_t restarts, const uint32_t num_restarts,
    const BlockHashIndex* hash_index, const BlockPrefixIndex* prefix_index,
    const size_t restart_block_cache_capacity) {
  DCHECK(data_ == nullptr); // Ensure it is called only once
  DCHECK_GT(num_restarts, 0); // Ensure the param is valid

  comparator_ = comparator;
  data_ = data;
  key_value_encoding_format_ = key_value_encoding_format;
  restarts_ = restarts;
  num_restarts_ = num_restarts;
  hash_index_ = hash_index;
  prefix_index_ = prefix_index;

  Reset();

  block_entry_cache_.clear();
  block_entry_cache_.reserve(std::max(restart_block_cache_capacity, kRestartBlockCacheMinSize));
  block_entry_cache_.emplace_back();

  // It is impossible to rely on restart_block_cache_'s capacity value, because that value cannot
  // be set to a value lower than the current one (in accordance with C++ stardard). That's why
  // a separate variable is required to understand if restart block keys caching is turned on.
  cache_restart_block_keys_ = restart_block_cache_capacity > 1;
}

const KeyValueEntry& BlockIter::Seek(Slice target) {
  PERF_TIMER_GUARD(block_seek_nanos);
  if (data_ == nullptr) {  // Not init yet
    return Entry();
  }

  uint32_t index = 0;
  bool ok = false;
  if (prefix_index_) {
    ok = PrefixSeek(target, &index);
  } else {
    ok = hash_index_ ? HashSeek(target, &index)
      : BinarySeek(target, 0, num_restarts_ - 1, &index);
  }

  if (!ok) {
    return Entry();
  }

  MoveToRestartBlock(index);

  // Linear search (within current restart block) for first key >= target
  while (ParseNextKey() && Compare(CurrentEntry().key_.GetKey(), target) < 0) {}
  return Entry();
}

const KeyValueEntry& BlockIter::SeekToFirst() {
  if (data_ == nullptr) {  // Not init yet
    return Entry();
  }

  MoveToRestartBlock(0);
  ParseNextKey();
  return Entry();
}

const KeyValueEntry& BlockIter::SeekToLast() {
  if (data_ == nullptr) {  // Not init yet
    return Entry();
  }

  MoveToRestartBlock(num_restarts_ - 1);
  while (ParseNextKey() && NextEntryOffset() < restarts_) {
    // Keep skipping
  }
  return Entry();
}

void BlockIter::SeekToRestart(uint32_t index) {
  if (data_ == nullptr) {  // Not init yet
    return;
  }
  if (PREDICT_FALSE((index >= num_restarts_))) {
    return SetStatus(STATUS(IllegalState, "Restart index overflow"));
  }

  MoveToRestartBlock(index);
  ParseNextKey();
}

ScanForwardResult BlockIter::ScanForward(
    const Comparator* user_key_comparator, const Slice& upperbound,
    KeyFilterCallback* key_filter_callback, ScanCallback* scan_callback) {
  LOG_IF(DFATAL, !Valid()) << "Iterator should be valid.";

  ScanForwardResult result;
  do {
    const auto user_key = ExtractUserKey(CurrentEntry().key_.GetKey());
    if (!upperbound.empty() && user_key_comparator->Compare(user_key, upperbound) >= 0) {
      break;
    }

    bool skip_key = false;
    if (key_filter_callback) {
      auto kf_result =
          (*key_filter_callback)(/*prefixed_key=*/ Slice(), /*shared_bytes=*/ 0, user_key);
      skip_key = kf_result.skip_key;
    }

    if (!skip_key) {
      if (!(*scan_callback)(user_key, CurrentEntry().entry_.value)) {
        result.reached_upperbound = false;
        return result;
      }
    }

    result.number_of_keys_visited++;
    Next();
  } while (Valid());

  result.reached_upperbound = true;
  return result;
}

namespace {

Status BadBlockContentsError() {
  return STATUS(Corruption, "bad block contents");
}

Status BadEntryInBlockError(const std::string& error_details) {
  return STATUS(Corruption, yb::Format("bad entry in block: $0", error_details));
}

} // namespace

void BlockIter::SetError(const Status& error) {
  SetInvalid();
  status_ = error;
}

void BlockIter::CorruptionError(const std::string& error_details) {
  SetError(BadEntryInBlockError(error_details));
}

namespace {

// This function decodes next key-value pair starting at p and encoded with three_shared_parts
// delta-encoding algorithm (see ThreeSharedPartsEncoder inside block_builder.cc).
// limit specifies exclusive upper bound on where we allowed to decode from.
//
// The function relies on *key to contain previous decoded key and updates it with a next one.
// *value is set to Slice pointing to corresponding key's value.
//
// Returns whether decoding was successful.
inline bool ParseNextKeyThreeSharedParts(
    const char* p, const char* limit, IterKey* key, Slice* value) {
  uint32_t shared_prefix_size, non_shared_1_size, non_shared_2_size, shared_last_component_size,
      value_size;
  bool is_something_shared;
  int64_t non_shared_1_size_delta, non_shared_2_size_delta;
  uint64_t shared_last_component_increase;

  p = DecodeEntryThreeSharedParts(
      p, limit, &shared_prefix_size, &non_shared_1_size,
      &non_shared_1_size_delta, &is_something_shared, &non_shared_2_size, &non_shared_2_size_delta,
      &shared_last_component_size, &shared_last_component_increase, &value_size);
  if (p == nullptr) {
    return false;
  }

  if (PREDICT_FALSE(!is_something_shared)) {
    // If this key doesn't share any bytes with prev key then we don't need
    // to decode it and can use its address in the block directly.
    key->SetKey(Slice(p, non_shared_1_size), false /* copy */);
    *value = Slice(p + non_shared_1_size, value_size);
    return true;
  }

  // The start offset of the shared middle part of the previous key.
  const auto prev_shared_middle_start =
      shared_prefix_size + non_shared_1_size - non_shared_1_size_delta;
  const auto prev_non_shared_2_size = non_shared_2_size - non_shared_2_size_delta;
  const auto prev_size_except_middle_shared = prev_shared_middle_start + prev_non_shared_2_size +
      shared_last_component_size;

  const auto key_size = static_cast<uint32_t>(key->Size());

  if (key_size < prev_size_except_middle_shared) {
    return false;
  }

  const auto shared_middle_size = key_size - prev_size_except_middle_shared;

  if ((shared_prefix_size + shared_middle_size + shared_last_component_size) == 0) {
    // This is an error, because is_something_shared is true.
    return false;
  }

  key->Update(
      p, shared_prefix_size, non_shared_1_size, static_cast<uint32_t>(prev_shared_middle_start),
      static_cast<uint32_t>(shared_middle_size), non_shared_2_size, shared_last_component_size,
      shared_last_component_increase);
  *value = Slice(p + non_shared_1_size + non_shared_2_size, value_size);
  return true;
}

} // namespace

bool BlockIter::ParseNextKey() {
  current_ = NextEntryOffset();
  const char* entry_data = data_ + current_;
  const char* data_end = data_ + restarts_;  // Restarts come right after data.

  if (entry_data >= data_end) {
    // No more entries to return. Mark as invalid.
    SetInvalid();
    return false;
  }

  // Restore the invariant that restart_block_idx_ is the index of the restart block in which
  // current entry falls.
  const auto last_restart_block_idx = restart_index_;
  while (restart_index_ + 1 < num_restarts_ &&
         GetRestartBlockOffset(restart_index_ + 1) <= current_) {
    ++restart_index_;
  }

  if (cache_restart_block_keys_) {
    if (restart_index_ != last_restart_block_idx) {
      // It is expected to be moved exactly to the next restart block.
      DCHECK_EQ(restart_index_, last_restart_block_idx + 1);

      // Cache position should be reset to fit all the entries from the new restart block.
      block_entry_cache_idx_ = 0;

      // Need to clean key_ as that cache element does not contain previously decoded key. And
      // it is OK to clean that key as each restart block starts with a full key.
      CurrentEntry().key_.Clear();
    } else if (CurrentEntry().entry_.Valid()) {
      // Cache expansion should be done only if the current element has already been initialized.
      // It is expected that only the first element in the cache could be unitialized right before
      // moving to a next or random restart block (see the sanity check in the next `else` block).

      // Sanity checks for current position must not exceed the number of available elements.
      DCHECK_LT(block_entry_cache_idx_, block_entry_cache_.size());

      // Using previously decoded key, as a base for next key delta.
      const auto base_key = CurrentEntry().entry_.key;

      // Move to a next slot in the cache and ensure it is allocated.
      if (++block_entry_cache_idx_ == block_entry_cache_.size()) {
        block_entry_cache_.emplace_back();
      }

      CurrentEntry().key_.SetKey(base_key);
    } else {
      // Sanity check for the current element is not yet initialized, which is expected to happen
      // for the very first element in the cache only.
      DCHECK_EQ(block_entry_cache_idx_, 0);
    }
  }

  // Decode next entry.
  bool valid_encoding_type = false;
  switch (key_value_encoding_format_) {
    case KeyValueEncodingFormat::kKeyDeltaEncodingSharedPrefix: {
      valid_encoding_type = true;
      uint32_t shared, non_shared, value_length;
      entry_data = DecodeEntry(entry_data, data_end, &shared, &non_shared, &value_length);
      if (entry_data == nullptr || CurrentEntry().key_.Size() < shared) {
        CorruptionError(yb::Format(
            "p: $0, key_.Size(): $1, shared: $2",
            static_cast<const void*>(entry_data),
            CurrentEntry().key_.Size(),
            shared));
        return false;
      }
      if (shared == 0) {
        // If this key dont share any bytes with prev key then we dont need
        // to decode it and can use it's address in the block directly.
        CurrentEntry().key_.SetKey(Slice(entry_data, non_shared), false /* copy */);
      } else {
        // This key share `shared` bytes with prev key, we need to decode it
        CurrentEntry().key_.TrimAppend(shared, entry_data, non_shared);
      }
      CurrentEntry().entry_ = KeyValueEntry {
        .key   = CurrentEntry().key_.GetKey(),
        .value = Slice(entry_data + non_shared, value_length),
      };
      break;
    }
    case KeyValueEncodingFormat::kKeyDeltaEncodingThreeSharedParts: {
      valid_encoding_type = true;
      if (!ParseNextKeyThreeSharedParts(
              entry_data, data_end, &CurrentEntry().key_, &CurrentEntry().entry_.value)) {
        CorruptionError("ParseNextKeyThreeSharedParts failed");
        return false;
      }
      CurrentEntry().entry_.key = CurrentEntry().key_.GetKey();
      break;
    }
  }

  if (!valid_encoding_type) {
    FATAL_INVALID_ENUM_VALUE(KeyValueEncodingFormat, key_value_encoding_format_);
  }

  return true;
}

// Binary search in restart array to find the first restart point
// with a key >= target (TODO: this comment is inaccurate)
bool BlockIter::BinarySeek(const Slice& target, uint32_t left, uint32_t right, uint32_t* index) {
  DCHECK_LE(left, right);

  while (left < right) {
    uint32_t mid = (left + right + 1) / 2;
    uint32_t region_offset = GetRestartBlockOffset(mid);
    uint32_t key_size;
    const char* key_ptr = DecodeRestartEntry(
        key_value_encoding_format_, data_ + region_offset, data_ + restarts_, data_, &key_size);
    if (key_ptr == nullptr) {
      CorruptionError("DecodeRestartEntry failed");
      return false;
    }
    Slice mid_key(key_ptr, key_size);
    int cmp = Compare(mid_key, target);
    if (cmp < 0) {
      // Key at "mid" is smaller than "target". Therefore all
      // blocks before "mid" are uninteresting.
      left = mid;
    } else if (cmp > 0) {
      // Key at "mid" is >= "target". Therefore all blocks at or
      // after "mid" are uninteresting.
      right = mid - 1;
    } else {
      left = right = mid;
    }
  }

  *index = left;
  return true;
}

// Compare target key and the block key of the block of `block_index`.
// Return -1 if error.
int BlockIter::CompareBlockKey(uint32_t block_index, const Slice& target) {
  uint32_t region_offset = GetRestartBlockOffset(block_index);
  uint32_t key_size;
  const char* key_ptr = DecodeRestartEntry(
      key_value_encoding_format_, data_ + region_offset, data_ + restarts_, data_, &key_size);
  if (key_ptr == nullptr) {
    CorruptionError("DecodeRestartEntry failed");
    return 1;  // Return target is smaller
  }
  Slice block_key(key_ptr, key_size);
  return Compare(block_key, target);
}

// Binary search in block_ids to find the first block
// with a key >= target
bool BlockIter::BinaryBlockIndexSeek(const Slice& target, uint32_t* block_ids,
                          uint32_t left, uint32_t right,
                          uint32_t* index) {
  DCHECK_LE(left, right);
  uint32_t left_bound = left;

  while (left <= right) {
    uint32_t mid = (left + right) / 2;

    int cmp = CompareBlockKey(block_ids[mid], target);
    if (!status_.ok()) {
      return false;
    }
    if (cmp < 0) {
      // Key at "target" is larger than "mid". Therefore all
      // blocks before or at "mid" are uninteresting.
      left = mid + 1;
    } else {
      // Key at "target" is <= "mid". Therefore all blocks
      // after "mid" are uninteresting.
      // If there is only one block left, we found it.
      if (left == right) break;
      right = mid;
    }
  }

  if (left == right) {
    // In one of the two following cases:
    // (1) left is the first one of block_ids
    // (2) there is a gap of blocks between block of `left` and `left-1`.
    // we can further distinguish the case of key in the block or key not
    // existing, by comparing the target key and the key of the previous
    // block to the left of the block found.
    if (block_ids[left] > 0 &&
        (left == left_bound || block_ids[left - 1] != block_ids[left] - 1) &&
        CompareBlockKey(block_ids[left] - 1, target) > 0) {
      SetInvalid();
      return false;
    }

    *index = block_ids[left];
    return true;
  } else {
    DCHECK_GT(left, right);
    // Mark iterator invalid.
    SetInvalid();
    return false;
  }
}

bool BlockIter::HashSeek(const Slice& target, uint32_t* index) {
  DCHECK_ONLY_NOTNULL(hash_index_);
  auto restart_index = hash_index_->GetRestartIndex(target);
  if (restart_index == nullptr) {
    SetInvalid();
    return false;
  }

  // The elements in restart_array[index : index + num_blocks]
  // are all with same prefix. We'll do binary search in that small range.
  auto left = restart_index->first_index;
  auto right = restart_index->first_index + restart_index->num_blocks - 1;
  return BinarySeek(target, left, right, index);
}

bool BlockIter::PrefixSeek(const Slice& target, uint32_t* index) {
  DCHECK_ONLY_NOTNULL(prefix_index_);
  uint32_t* block_ids = nullptr;
  uint32_t num_blocks = prefix_index_->GetBlocks(target, &block_ids);

  if (num_blocks == 0) {
    SetInvalid();
    return false;
  }

  return BinaryBlockIndexSeek(target, block_ids, 0, num_blocks - 1, index);
}

uint32_t Block::NumRestarts() const {
  DCHECK_GE(size_, kMinBlockSize);
  return DecodeFixed32(data_ + size_ - sizeof(uint32_t));
}

Block::Block(BlockContents&& contents)
    : contents_(std::move(contents)),
      data_(contents_.data.cdata()),
      size_(contents_.data.size()) {
  if (size_ < sizeof(uint32_t)) {
    size_ = 0;  // Error marker
  } else {
    restart_offset_ =
        static_cast<uint32_t>(size_) - (1 + NumRestarts()) * sizeof(uint32_t);
    if (restart_offset_ > size_ - sizeof(uint32_t)) {
      // The size is too small for NumRestarts() and therefore
      // restart_offset_ wrapped around.
      size_ = 0;
    }
  }
}

InternalIterator* Block::NewIterator(
    const Comparator* cmp, const KeyValueEncodingFormat key_value_encoding_format, BlockIter* iter,
    const bool total_order_seek, const size_t restart_block_cache_capacity) const {
  if (size_ < kMinBlockSize) {
    if (iter != nullptr) {
      iter->SetStatus(BadBlockContentsError());
      return iter;
    } else {
      return NewErrorInternalIterator(BadBlockContentsError());
    }
  }
  const uint32_t num_restarts = NumRestarts();
  if (num_restarts == 0) {
    if (iter != nullptr) {
      iter->SetStatus(Status::OK());
      return iter;
    } else {
      return NewEmptyInternalIterator();
    }
  } else {
    BlockHashIndex* hash_index_ptr =
        total_order_seek ? nullptr : hash_index_.get();
    BlockPrefixIndex* prefix_index_ptr =
        total_order_seek ? nullptr : prefix_index_.get();

    if (iter != nullptr) {
      iter->Initialize(cmp, data_, key_value_encoding_format, restart_offset_, num_restarts,
                    hash_index_ptr, prefix_index_ptr, restart_block_cache_capacity);
    } else {
      iter = new BlockIter(cmp, data_, key_value_encoding_format, restart_offset_, num_restarts,
                           hash_index_ptr, prefix_index_ptr, restart_block_cache_capacity);
    }
  }

  return iter;
}

void Block::SetBlockHashIndex(BlockHashIndex* hash_index) {
  hash_index_.reset(hash_index);
}

void Block::SetBlockPrefixIndex(BlockPrefixIndex* prefix_index) {
  prefix_index_.reset(prefix_index);
}

size_t Block::ApproximateMemoryUsage() const {
  size_t usage = usable_size();
  if (hash_index_) {
    usage += hash_index_->ApproximateMemoryUsage();
  }
  if (prefix_index_) {
    usage += prefix_index_->ApproximateMemoryUsage();
  }
  return usage;
}

yb::Result<std::string> Block::GetRestartBlockMiddleEntryKey(
    const uint32_t restart_idx, const Comparator* comparator,
    const KeyValueEncodingFormat key_value_encoding_format,
    const MiddlePointPolicy middle_restart_policy) const {
  BlockIter block_iter;
  NewIterator(comparator, key_value_encoding_format, &block_iter, /* total_order_seek = */ true);
  RETURN_NOT_OK(block_iter.status());

  // Linear scan is required to locate a middle entry within the restart point.
  // First step is to find number of records within for the restart point.
  uint32_t records_count = 0;
  for (block_iter.SeekToRestart(restart_idx);
       block_iter.Valid() && (block_iter.GetCurrentRestart() == restart_idx);
       block_iter.Next()) {
    RETURN_NOT_OK(block_iter.status());
    ++records_count;
  }
  RETURN_NOT_OK(block_iter.status());

  if (records_count < 2) {
    // Not possible to identify a middle entry when there is 0 or 1 record in a block. Also
    // including one record to a check allows to use the error as a marker of a single data block.
    return STATUS(
        Incomplete, yb::Format("Less than 2 entries ($0) in restart block", records_count));
  }

  // Second step is to advance to the middle record.
  const auto middle_record_idx = GetMiddleIndex(records_count, middle_restart_policy);
  for (block_iter.SeekToFirst(), records_count = 0;
       block_iter.Valid() && (records_count < middle_record_idx);
       block_iter.Next()) {
    RETURN_NOT_OK(block_iter.status());
    ++records_count;
  }
  RETURN_NOT_OK(block_iter.status());

  // Must read exactly up to a middle record.
  if (PREDICT_FALSE((records_count != middle_record_idx))) {
    return STATUS(IllegalState, "Failed to locate middle record for the restart block");
  }

  // The iterator now points to a middle entry of the specified restart block.
  return block_iter.key().ToBuffer();
}

yb::Result<Slice> Block::GetRestartKey(
    const uint32_t restart_idx, const KeyValueEncodingFormat key_value_encoding_format) const {
  if (size_ < kMinBlockSize) {
    return BadBlockContentsError();
  } else if (size_ == kMinBlockSize) {
    return STATUS(Incomplete, "Empty block");
  } else if (restart_idx >= NumRestarts()) {
    return STATUS(IllegalState,
        yb::Format("Restart index overflow: idx = $0, total num = $1", restart_idx, NumRestarts()));
  }

  const auto entry_offset = DecodeFixed32(data_ + restart_offset_ + restart_idx * sizeof(uint32_t));
  uint32_t key_size;
  const char* key_ptr = DecodeRestartEntry(
      key_value_encoding_format, data_ + entry_offset, data_ + restart_offset_, data_, &key_size);
  if (key_ptr == nullptr) {
    return BadEntryInBlockError("DecodeRestartEntry failed");
  }

  return Slice(key_ptr, key_size);
}

yb::Result<std::string> Block::GetMiddleKey(
    const KeyValueEncodingFormat key_value_encoding_format, const Comparator* cmp,
    const MiddlePointPolicy middle_entry_policy) const {
  if (PREDICT_FALSE((NumRestarts() == 0))) {
    // Not possible to have less than 1 restart at all, refer to the BlockBuilder's constuctor.
    return STATUS(Corruption, "Restarts number cannot be zero, this might be a data corruption!");
  }
  if (PREDICT_TRUE(NumRestarts() > 1)) {
    const auto restart_idx = GetMiddleIndex(NumRestarts(), middle_entry_policy);
    const auto middle_key =
        VERIFY_RESULT(GetRestartKey(restart_idx, key_value_encoding_format));
    return middle_key.ToBuffer();
  }

  // Special case for single restart block.
  return VERIFY_RESULT(GetRestartBlockMiddleEntryKey(
      /* restart_idx = */ 0, cmp, key_value_encoding_format, middle_entry_policy));
}

}  // namespace rocksdb
